{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificaci√≥n de Sonidos Ambientales con ResNet-50\n",
    "## Pr√°ctica: Dataset ESC-50 + Transfer Learning\n",
    "\n",
    "### Objetivo\n",
    "Clasificar sonidos ambientales del dataset ESC-50 utilizando el modelo ResNet-50 pre-entrenado en ImageNet.\n",
    "\n",
    "### ¬øPor qu√© funciona esto?\n",
    "ResNet-50 est√° dise√±ado para clasificar im√°genes, pero los sonidos pueden convertirse en **espectrogramas** (representaciones visuales del audio). As√≠, aprovechamos el conocimiento que ResNet-50 aprendi√≥ de millones de im√°genes para clasificar sonidos.\n",
    "\n",
    "### Flujo del proyecto:\n",
    "1. **Descargar** el dataset ESC-50\n",
    "2. **Convertir** audios a espectrogramas (im√°genes)\n",
    "3. **Adaptar** ResNet-50 para 50 clases de sonidos\n",
    "4. **Entrenar** el modelo\n",
    "5. **Evaluar** los resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Instalaci√≥n de Dependencias\n",
    "\n",
    "Primero instalamos las librer√≠as necesarias si no las tienes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalamos las librer√≠as necesarias\n",
    "# - torch y torchvision: Framework de deep learning de PyTorch\n",
    "# - torchaudio: Procesamiento de audio con PyTorch\n",
    "# - librosa: Librer√≠a especializada en an√°lisis de audio\n",
    "# - matplotlib: Para crear gr√°ficos y visualizaciones\n",
    "# - pandas: Manipulaci√≥n de datos tabulares\n",
    "# - tqdm: Barras de progreso bonitas\n",
    "\n",
    "!pip install torch torchvision torchaudio librosa matplotlib pandas tqdm scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Importaci√≥n de Librer√≠as\n",
    "\n",
    "Importamos todo lo necesario con explicaciones detalladas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# IMPORTACIONES PRINCIPALES\n",
    "# ============================================================\n",
    "\n",
    "# --- Librer√≠as est√°ndar de Python ---\n",
    "import os                    # Operaciones con el sistema de archivos (rutas, directorios)\n",
    "import urllib.request        # Para descargar archivos de internet\n",
    "import zipfile               # Para descomprimir archivos .zip\n",
    "import warnings              # Para controlar mensajes de advertencia\n",
    "warnings.filterwarnings('ignore')  # Silenciamos advertencias molestas\n",
    "\n",
    "# --- Librer√≠as de datos ---\n",
    "import numpy as np           # Operaciones num√©ricas con arrays (vectores y matrices)\n",
    "import pandas as pd          # Manipulaci√≥n de datos en formato tabla (DataFrames)\n",
    "\n",
    "# --- Librer√≠as de audio ---\n",
    "import librosa               # An√°lisis y procesamiento de audio\n",
    "import librosa.display       # Visualizaci√≥n de espectrogramas\n",
    "\n",
    "# --- Librer√≠as de visualizaci√≥n ---\n",
    "import matplotlib.pyplot as plt  # Crear gr√°ficos\n",
    "\n",
    "# --- PyTorch: Framework de Deep Learning ---\n",
    "import torch                            # Librer√≠a principal de PyTorch\n",
    "import torch.nn as nn                   # M√≥dulos de redes neuronales (capas, funciones)\n",
    "import torch.optim as optim             # Optimizadores (SGD, Adam, etc.)\n",
    "from torch.utils.data import Dataset, DataLoader  # Clases para manejar datos\n",
    "\n",
    "# --- TorchVision: Modelos y transformaciones de im√°genes ---\n",
    "import torchvision.models as models     # Modelos pre-entrenados (ResNet, VGG, etc.)\n",
    "import torchvision.transforms as transforms  # Transformaciones de im√°genes\n",
    "\n",
    "# --- Utilidades ---\n",
    "from tqdm import tqdm                   # Barras de progreso\n",
    "from sklearn.model_selection import train_test_split  # Divisi√≥n train/test\n",
    "from sklearn.metrics import confusion_matrix, classification_report  # M√©tricas\n",
    "\n",
    "# --- Configuraci√≥n del dispositivo ---\n",
    "# PyTorch puede usar GPU (CUDA) para acelerar el entrenamiento\n",
    "# Si tienes GPU NVIDIA, usar√° CUDA; si no, usar√° CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üñ•Ô∏è  Dispositivo seleccionado: {device}\")\n",
    "print(f\"üì¶ PyTorch versi√≥n: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Descarga del Dataset ESC-50\n",
    "\n",
    "### ¬øQu√© es ESC-50?\n",
    "- **2000 grabaciones** de audio de 5 segundos cada una\n",
    "- **50 clases** de sonidos ambientales (perro, lluvia, reloj, etc.)\n",
    "- **40 clips por clase**\n",
    "- Organizado en **5 folds** para validaci√≥n cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DESCARGA DEL DATASET ESC-50\n",
    "# ============================================================\n",
    "\n",
    "# URL del dataset en GitHub (archivo ZIP)\n",
    "ESC50_URL = \"https://github.com/karoldvl/ESC-50/archive/master.zip\"\n",
    "\n",
    "# Directorio donde guardaremos los datos\n",
    "DATA_DIR = \"data\"           # Carpeta principal de datos\n",
    "ZIP_PATH = \"data/esc50.zip\" # Ruta donde guardaremos el ZIP descargado\n",
    "\n",
    "def descargar_esc50():\n",
    "    \"\"\"\n",
    "    Descarga y extrae el dataset ESC-50 si no existe.\n",
    "    \n",
    "    Returns:\n",
    "        str: Ruta al directorio del dataset extra√≠do\n",
    "    \"\"\"\n",
    "    # Creamos el directorio 'data' si no existe\n",
    "    # exist_ok=True evita error si ya existe\n",
    "    os.makedirs(DATA_DIR, exist_ok=True)\n",
    "    \n",
    "    # Ruta donde estar√° el dataset una vez extra√≠do\n",
    "    dataset_path = os.path.join(DATA_DIR, \"ESC-50-master\")\n",
    "    \n",
    "    # Verificamos si ya tenemos el dataset descargado\n",
    "    if os.path.exists(dataset_path):\n",
    "        print(\"‚úÖ Dataset ESC-50 ya existe. No es necesario descargar.\")\n",
    "        return dataset_path\n",
    "    \n",
    "    # Si no existe, lo descargamos\n",
    "    print(\"‚¨áÔ∏è  Descargando dataset ESC-50 (600+ MB)...\")\n",
    "    print(\"   Esto puede tardar varios minutos dependiendo de tu conexi√≥n.\")\n",
    "    \n",
    "    # urllib.request.urlretrieve descarga un archivo de una URL\n",
    "    # Primer argumento: URL de origen\n",
    "    # Segundo argumento: ruta donde guardar el archivo\n",
    "    urllib.request.urlretrieve(ESC50_URL, ZIP_PATH)\n",
    "    print(\"‚úÖ Descarga completada.\")\n",
    "    \n",
    "    # Extraemos el contenido del ZIP\n",
    "    print(\"üì¶ Extrayendo archivos...\")\n",
    "    \n",
    "    # zipfile.ZipFile abre el archivo ZIP\n",
    "    # 'r' significa modo lectura\n",
    "    with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:\n",
    "        # extractall extrae todos los archivos al directorio especificado\n",
    "        zip_ref.extractall(DATA_DIR)\n",
    "    \n",
    "    print(\"‚úÖ Extracci√≥n completada.\")\n",
    "    \n",
    "    # Eliminamos el ZIP para ahorrar espacio\n",
    "    os.remove(ZIP_PATH)\n",
    "    print(\"üóëÔ∏è  Archivo ZIP eliminado para ahorrar espacio.\")\n",
    "    \n",
    "    return dataset_path\n",
    "\n",
    "# Ejecutamos la funci√≥n y guardamos la ruta\n",
    "DATASET_PATH = descargar_esc50()\n",
    "print(f\"\\nüìÅ Dataset ubicado en: {DATASET_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Exploraci√≥n del Dataset (EDA)\n",
    "\n",
    "Antes de entrenar, es fundamental **entender nuestros datos**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CARGA DE METADATOS\n",
    "# ============================================================\n",
    "\n",
    "# El dataset incluye un archivo CSV con informaci√≥n de cada audio\n",
    "# Este archivo contiene: nombre del archivo, fold, categor√≠a, etc.\n",
    "meta_path = os.path.join(DATASET_PATH, \"meta\", \"esc50.csv\")\n",
    "\n",
    "# pd.read_csv lee un archivo CSV y lo convierte en DataFrame\n",
    "# Un DataFrame es como una tabla de Excel en Python\n",
    "df = pd.read_csv(meta_path)\n",
    "\n",
    "# Mostramos las primeras 5 filas para ver la estructura\n",
    "print(\"üìã Primeras filas del dataset:\")\n",
    "print(\"=\"*60)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# AN√ÅLISIS B√ÅSICO DEL DATASET\n",
    "# ============================================================\n",
    "\n",
    "print(\"üìä ESTAD√çSTICAS DEL DATASET ESC-50\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# .shape nos da (filas, columnas) del DataFrame\n",
    "print(f\"\\nüìÅ Total de archivos de audio: {df.shape[0]}\")\n",
    "\n",
    "# .nunique() cuenta valores √∫nicos en una columna\n",
    "print(f\"üè∑Ô∏è  N√∫mero de categor√≠as: {df['category'].nunique()}\")\n",
    "\n",
    "# N√∫mero de folds (para validaci√≥n cruzada)\n",
    "print(f\"üìÇ N√∫mero de folds: {df['fold'].nunique()}\")\n",
    "\n",
    "# Contamos cu√°ntos audios hay por categor√≠a\n",
    "print(f\"\\nüî¢ Audios por categor√≠a:\")\n",
    "# value_counts() cuenta ocurrencias de cada valor √∫nico\n",
    "print(df['category'].value_counts().head(10))  # Mostramos solo 10\n",
    "\n",
    "print(\"\\nüí° Observaci√≥n: Cada categor√≠a tiene exactamente 40 muestras (dataset balanceado)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# LISTADO DE TODAS LAS CATEGOR√çAS\n",
    "# ============================================================\n",
    "\n",
    "print(\"üè∑Ô∏è  LAS 50 CATEGOR√çAS DEL DATASET ESC-50:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# .unique() devuelve un array con los valores √∫nicos\n",
    "# sorted() los ordena alfab√©ticamente\n",
    "categorias = sorted(df['category'].unique())\n",
    "\n",
    "# Mostramos las categor√≠as en formato de tabla (5 columnas)\n",
    "for i, cat in enumerate(categorias, 1):  # enumerate a√±ade √≠ndice, empezando en 1\n",
    "    # end=' ' evita el salto de l√≠nea\n",
    "    # ljust(20) a√±ade espacios para alinear (20 caracteres de ancho)\n",
    "    print(f\"{i:2d}. {cat.ljust(20)}\", end='')\n",
    "    # Cada 3 categor√≠as, saltamos de l√≠nea\n",
    "    if i % 3 == 0:\n",
    "        print()  # Nueva l√≠nea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# VISUALIZACI√ìN DE UNA ONDA DE AUDIO\n",
    "# ============================================================\n",
    "\n",
    "# Ruta a los archivos de audio\n",
    "audio_dir = os.path.join(DATASET_PATH, \"audio\")\n",
    "\n",
    "# Tomamos un archivo de ejemplo (el primero del DataFrame)\n",
    "ejemplo_archivo = df.iloc[0]['filename']  # iloc[0] = primera fila\n",
    "ejemplo_categoria = df.iloc[0]['category']\n",
    "ejemplo_path = os.path.join(audio_dir, ejemplo_archivo)\n",
    "\n",
    "print(f\"üéµ Analizando: {ejemplo_archivo}\")\n",
    "print(f\"üìÅ Categor√≠a: {ejemplo_categoria}\")\n",
    "\n",
    "# librosa.load() carga un archivo de audio\n",
    "# Retorna:\n",
    "#   - y: numpy array con los valores de amplitud de la onda\n",
    "#   - sr: sample rate (muestras por segundo, t√≠picamente 22050 Hz)\n",
    "y, sr = librosa.load(ejemplo_path, sr=None)  # sr=None mantiene el sample rate original\n",
    "\n",
    "print(f\"\\nüìä Informaci√≥n del audio:\")\n",
    "print(f\"   - Sample rate: {sr} Hz (muestras por segundo)\")\n",
    "print(f\"   - Duraci√≥n: {len(y)/sr:.2f} segundos\")\n",
    "print(f\"   - Total de muestras: {len(y):,}\")\n",
    "\n",
    "# Creamos una figura para visualizar\n",
    "plt.figure(figsize=(14, 4))  # Tama√±o: 14 pulgadas de ancho, 4 de alto\n",
    "\n",
    "# librosa.display.waveshow muestra la forma de onda\n",
    "librosa.display.waveshow(y, sr=sr, alpha=0.8)  # alpha = transparencia\n",
    "\n",
    "plt.title(f'Forma de Onda: {ejemplo_categoria}', fontsize=14)\n",
    "plt.xlabel('Tiempo (segundos)')\n",
    "plt.ylabel('Amplitud')\n",
    "plt.tight_layout()  # Ajusta los m√°rgenes autom√°ticamente\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Conversi√≥n de Audio a Espectrogramas\n",
    "\n",
    "### ¬øQu√© es un espectrograma?\n",
    "Un **espectrograma** es una representaci√≥n visual del audio que muestra:\n",
    "- **Eje X**: Tiempo\n",
    "- **Eje Y**: Frecuencia (Hz)\n",
    "- **Color**: Intensidad/Energ√≠a\n",
    "\n",
    "### ¬øPor qu√© Mel-Espectrogramas?\n",
    "La escala **Mel** imita c√≥mo el o√≠do humano percibe frecuencias. Escuchamos mejor diferencias en frecuencias bajas que en altas. La escala Mel compensa esto.\n",
    "\n",
    "### Esto es clave porque:\n",
    "ResNet-50 espera **im√°genes**. Al convertir audio ‚Üí espectrograma, transformamos el problema de audio en un problema de visi√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# FUNCI√ìN PARA CREAR MEL-ESPECTROGRAMAS\n",
    "# ============================================================\n",
    "\n",
    "def audio_a_mel_espectrograma(ruta_audio, sr=22050, n_mels=128, duracion_fija=5.0):\n",
    "    \"\"\"\n",
    "    Convierte un archivo de audio en un Mel-espectrograma.\n",
    "    \n",
    "    Par√°metros:\n",
    "    -----------\n",
    "    ruta_audio : str\n",
    "        Ruta al archivo de audio (.wav, .mp3, etc.)\n",
    "    \n",
    "    sr : int (default=22050)\n",
    "        Sample rate deseado. 22050 Hz es est√°ndar para an√°lisis de audio.\n",
    "        Significa 22,050 muestras por segundo.\n",
    "    \n",
    "    n_mels : int (default=128)\n",
    "        N√∫mero de bandas Mel. M√°s bandas = m√°s detalle en frecuencias.\n",
    "        128 es un valor com√∫n que balancea detalle y eficiencia.\n",
    "    \n",
    "    duracion_fija : float (default=5.0)\n",
    "        Duraci√≥n en segundos. ESC-50 tiene audios de 5 segundos.\n",
    "        Forzamos esta duraci√≥n para tener espectrogramas del mismo tama√±o.\n",
    "    \n",
    "    Retorna:\n",
    "    --------\n",
    "    numpy.ndarray\n",
    "        Mel-espectrograma en escala de decibelios (dB)\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- Paso 1: Cargar el audio ---\n",
    "    # librosa.load carga el audio y lo remuestrea al sr especificado\n",
    "    # duration=duracion_fija corta o rellena para tener exactamente 5 segundos\n",
    "    y, sr = librosa.load(ruta_audio, sr=sr, duration=duracion_fija)\n",
    "    \n",
    "    # --- Paso 2: Asegurar longitud fija ---\n",
    "    # Calculamos cu√°ntas muestras necesitamos para 5 segundos\n",
    "    longitud_objetivo = int(sr * duracion_fija)\n",
    "    \n",
    "    # Si el audio es m√°s corto, rellenamos con ceros (silencio)\n",
    "    if len(y) < longitud_objetivo:\n",
    "        # np.pad a√±ade ceros al final del array\n",
    "        # (0, longitud_objetivo - len(y)) = 0 ceros al inicio, el resto al final\n",
    "        y = np.pad(y, (0, longitud_objetivo - len(y)), mode='constant')\n",
    "    else:\n",
    "        # Si es m√°s largo, lo cortamos\n",
    "        y = y[:longitud_objetivo]\n",
    "    \n",
    "    # --- Paso 3: Calcular el Mel-espectrograma ---\n",
    "    # librosa.feature.melspectrogram calcula el espectrograma\n",
    "    # Par√°metros:\n",
    "    #   - y: se√±al de audio\n",
    "    #   - sr: sample rate\n",
    "    #   - n_mels: n√∫mero de bandas Mel\n",
    "    #   - n_fft: tama√±o de la ventana FFT (2048 es est√°ndar)\n",
    "    #   - hop_length: salto entre ventanas (512 = 75% de solapamiento)\n",
    "    mel_spec = librosa.feature.melspectrogram(\n",
    "        y=y,              # Se√±al de audio\n",
    "        sr=sr,            # Sample rate\n",
    "        n_mels=n_mels,    # Bandas de frecuencia Mel\n",
    "        n_fft=2048,       # Tama√±o de ventana FFT\n",
    "        hop_length=512    # Salto entre ventanas\n",
    "    )\n",
    "    \n",
    "    # --- Paso 4: Convertir a escala de decibelios ---\n",
    "    # Los valores crudos var√≠an mucho. La escala dB es m√°s manejable.\n",
    "    # librosa.power_to_db convierte potencia a decibelios\n",
    "    # ref=np.max normaliza respecto al valor m√°ximo\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    \n",
    "    return mel_spec_db\n",
    "\n",
    "print(\"‚úÖ Funci√≥n audio_a_mel_espectrograma definida correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# VISUALIZACI√ìN DE MEL-ESPECTROGRAMAS\n",
    "# ============================================================\n",
    "\n",
    "# Seleccionamos 4 ejemplos de diferentes categor√≠as para visualizar\n",
    "# Tomamos uno de cada categor√≠a diferente\n",
    "ejemplos = df.groupby('category').first().reset_index().head(4)\n",
    "\n",
    "# Creamos una figura con 4 subplots (2 filas x 2 columnas)\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "# flatten() convierte la matriz 2x2 de axes en un array 1D para iterar f√°cilmente\n",
    "axes = axes.flatten()\n",
    "\n",
    "print(\"üé® Generando Mel-espectrogramas de ejemplo...\\n\")\n",
    "\n",
    "for idx, (_, fila) in enumerate(ejemplos.iterrows()):\n",
    "    # Construimos la ruta completa al archivo de audio\n",
    "    ruta = os.path.join(audio_dir, fila['filename'])\n",
    "    categoria = fila['category']\n",
    "    \n",
    "    # Generamos el mel-espectrograma\n",
    "    mel_spec = audio_a_mel_espectrograma(ruta)\n",
    "    \n",
    "    # Visualizamos en el subplot correspondiente\n",
    "    # librosa.display.specshow es ideal para espectrogramas\n",
    "    img = librosa.display.specshow(\n",
    "        mel_spec,                    # Datos del espectrograma\n",
    "        x_axis='time',               # Eje X muestra tiempo\n",
    "        y_axis='mel',                # Eje Y muestra frecuencias Mel\n",
    "        sr=22050,                    # Sample rate\n",
    "        hop_length=512,              # Mismo hop_length usado al crear\n",
    "        ax=axes[idx],                # En qu√© subplot dibujar\n",
    "        cmap='viridis'               # Mapa de colores (viridis es muy legible)\n",
    "    )\n",
    "    \n",
    "    axes[idx].set_title(f'Categor√≠a: {categoria}', fontsize=12)\n",
    "    \n",
    "    # A√±adimos barra de color para interpretar la intensidad\n",
    "    fig.colorbar(img, ax=axes[idx], format='%+2.0f dB')\n",
    "\n",
    "plt.suptitle('Mel-Espectrogramas de Diferentes Categor√≠as', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Observa c√≥mo cada tipo de sonido tiene un 'patr√≥n visual' √∫nico.\")\n",
    "print(\"   ResNet-50 aprender√° a reconocer estos patrones.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Preparaci√≥n de Datos para PyTorch\n",
    "\n",
    "### ¬øQu√© es un Dataset en PyTorch?\n",
    "Un `Dataset` es una clase que define:\n",
    "1. **`__len__`**: Cu√°ntos elementos hay\n",
    "2. **`__getitem__`**: C√≥mo obtener un elemento por √≠ndice\n",
    "\n",
    "### ¬øQu√© es un DataLoader?\n",
    "Un `DataLoader` es un iterador que:\n",
    "- Agrupa datos en **batches** (lotes)\n",
    "- Puede **mezclar** los datos (shuffle)\n",
    "- Carga datos en **paralelo** (num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DATASET PERSONALIZADO PARA ESC-50\n",
    "# ============================================================\n",
    "\n",
    "class ESC50Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset personalizado para ESC-50 que convierte audios a espectrogramas.\n",
    "    \n",
    "    Esta clase hereda de torch.utils.data.Dataset y permite:\n",
    "    - Cargar audios bajo demanda (no todos a memoria)\n",
    "    - Aplicar transformaciones (resize, normalizaci√≥n)\n",
    "    - Integrarse con DataLoader para batching\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dataframe, audio_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Inicializa el dataset.\n",
    "        \n",
    "        Par√°metros:\n",
    "        -----------\n",
    "        dataframe : pd.DataFrame\n",
    "            DataFrame con columnas 'filename' y 'target'\n",
    "        \n",
    "        audio_dir : str\n",
    "            Directorio donde est√°n los archivos de audio\n",
    "        \n",
    "        transform : callable, opcional\n",
    "            Transformaciones a aplicar a cada espectrograma\n",
    "        \"\"\"\n",
    "        # Guardamos el DataFrame como atributo de la instancia\n",
    "        self.dataframe = dataframe.reset_index(drop=True)\n",
    "        \n",
    "        # Directorio con los audios\n",
    "        self.audio_dir = audio_dir\n",
    "        \n",
    "        # Transformaciones (resize, normalizaci√≥n, etc.)\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Creamos un mapeo de categor√≠a a √≠ndice num√©rico\n",
    "        # Ejemplo: {'dog': 0, 'rain': 1, ...}\n",
    "        self.categorias = sorted(dataframe['category'].unique())\n",
    "        self.categoria_a_idx = {cat: idx for idx, cat in enumerate(self.categorias)}\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Retorna el n√∫mero total de muestras en el dataset.\n",
    "        PyTorch usa esto para saber cu√°ntos datos hay.\n",
    "        \"\"\"\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Obtiene un elemento por su √≠ndice.\n",
    "        \n",
    "        Este m√©todo es llamado por el DataLoader cuando necesita un dato.\n",
    "        \n",
    "        Par√°metros:\n",
    "        -----------\n",
    "        idx : int\n",
    "            √çndice del elemento a obtener\n",
    "        \n",
    "        Retorna:\n",
    "        --------\n",
    "        tuple (tensor, int)\n",
    "            - tensor: Espectrograma como tensor de PyTorch\n",
    "            - int: Etiqueta (√≠ndice de la categor√≠a)\n",
    "        \"\"\"\n",
    "        # Obtenemos la fila correspondiente del DataFrame\n",
    "        fila = self.dataframe.iloc[idx]\n",
    "        \n",
    "        # Construimos la ruta completa al archivo de audio\n",
    "        ruta_audio = os.path.join(self.audio_dir, fila['filename'])\n",
    "        \n",
    "        # Obtenemos la etiqueta (√≠ndice num√©rico de la categor√≠a)\n",
    "        etiqueta = self.categoria_a_idx[fila['category']]\n",
    "        \n",
    "        # Convertimos el audio a mel-espectrograma\n",
    "        mel_spec = audio_a_mel_espectrograma(ruta_audio)\n",
    "        \n",
    "        # Normalizamos el espectrograma al rango [0, 1]\n",
    "        # Esto es importante para que la red neuronal funcione bien\n",
    "        mel_spec = (mel_spec - mel_spec.min()) / (mel_spec.max() - mel_spec.min() + 1e-8)\n",
    "        \n",
    "        # Convertimos a tensor de PyTorch\n",
    "        # np.float32 porque PyTorch trabaja con float32 por defecto\n",
    "        mel_spec = torch.tensor(mel_spec, dtype=torch.float32)\n",
    "        \n",
    "        # A√±adimos dimensi√≥n de canal: (H, W) -> (1, H, W)\n",
    "        # ResNet espera (C, H, W) donde C=canales, H=alto, W=ancho\n",
    "        # Nuestro espectrograma es como una imagen en escala de grises (1 canal)\n",
    "        mel_spec = mel_spec.unsqueeze(0)  # unsqueeze a√±ade una dimensi√≥n\n",
    "        \n",
    "        # ResNet-50 espera 3 canales (RGB), as√≠ que replicamos el espectrograma\n",
    "        # (1, H, W) -> (3, H, W)\n",
    "        mel_spec = mel_spec.repeat(3, 1, 1)  # Repetimos 3 veces en la dimensi√≥n del canal\n",
    "        \n",
    "        # Aplicamos transformaciones adicionales si existen\n",
    "        if self.transform:\n",
    "            mel_spec = self.transform(mel_spec)\n",
    "        \n",
    "        return mel_spec, etiqueta\n",
    "\n",
    "print(\"‚úÖ Clase ESC50Dataset definida correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# TRANSFORMACIONES PARA LAS IM√ÅGENES\n",
    "# ============================================================\n",
    "\n",
    "# ResNet-50 fue entrenado con im√°genes de 224x224 p√≠xeles\n",
    "# Tambi√©n espera cierta normalizaci√≥n espec√≠fica\n",
    "\n",
    "# transforms.Compose encadena m√∫ltiples transformaciones\n",
    "transformaciones = transforms.Compose([\n",
    "    # Redimensiona la imagen a 224x224 (tama√±o que espera ResNet)\n",
    "    transforms.Resize((224, 224)),\n",
    "    \n",
    "    # Normalizaci√≥n con media y desviaci√≥n est√°ndar de ImageNet\n",
    "    # Estos valores son los que us√≥ ResNet durante su entrenamiento\n",
    "    # Es crucial usar los mismos para que el transfer learning funcione\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],  # Media de ImageNet por canal (R, G, B)\n",
    "        std=[0.229, 0.224, 0.225]    # Desviaci√≥n est√°ndar de ImageNet\n",
    "    )\n",
    "])\n",
    "\n",
    "print(\"‚úÖ Transformaciones definidas:\")\n",
    "print(\"   1. Resize a 224x224 (tama√±o de entrada de ResNet)\")\n",
    "print(\"   2. Normalizaci√≥n con estad√≠sticas de ImageNet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DIVISI√ìN EN CONJUNTOS DE ENTRENAMIENTO Y VALIDACI√ìN\n",
    "# ============================================================\n",
    "\n",
    "# ESC-50 tiene 5 folds predefinidos para validaci√≥n cruzada\n",
    "# Por simplicidad, usaremos folds 1-4 para entrenar y fold 5 para validar\n",
    "\n",
    "# Separamos el DataFrame seg√∫n el fold\n",
    "# df['fold'] != 5 selecciona todas las filas donde fold no es 5\n",
    "df_train = df[df['fold'] != 5].copy()  # Folds 1, 2, 3, 4 para entrenar\n",
    "df_val = df[df['fold'] == 5].copy()    # Fold 5 para validar\n",
    "\n",
    "print(\"üìä Divisi√≥n del dataset:\")\n",
    "print(f\"   - Entrenamiento: {len(df_train)} muestras (folds 1-4)\")\n",
    "print(f\"   - Validaci√≥n: {len(df_val)} muestras (fold 5)\")\n",
    "print(f\"   - Ratio: {len(df_train)/(len(df_train)+len(df_val))*100:.0f}% / {len(df_val)/(len(df_train)+len(df_val))*100:.0f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CREACI√ìN DE DATASETS Y DATALOADERS\n",
    "# ============================================================\n",
    "\n",
    "# Creamos instancias del Dataset para train y validaci√≥n\n",
    "dataset_train = ESC50Dataset(\n",
    "    dataframe=df_train,           # DataFrame con los datos de entrenamiento\n",
    "    audio_dir=audio_dir,          # Directorio con los audios\n",
    "    transform=transformaciones    # Transformaciones a aplicar\n",
    ")\n",
    "\n",
    "dataset_val = ESC50Dataset(\n",
    "    dataframe=df_val,\n",
    "    audio_dir=audio_dir,\n",
    "    transform=transformaciones\n",
    ")\n",
    "\n",
    "# Definimos el tama√±o del batch\n",
    "# Un batch m√°s grande = entrenamiento m√°s estable pero m√°s memoria\n",
    "# 16 o 32 son valores comunes para GPUs de consumo\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Creamos los DataLoaders\n",
    "# DataLoader se encarga de:\n",
    "# - Agrupar datos en batches\n",
    "# - Mezclar datos (shuffle) en entrenamiento\n",
    "# - Cargar datos en paralelo (num_workers)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset_train,           # Dataset a usar\n",
    "    batch_size=BATCH_SIZE,   # Tama√±o del batch\n",
    "    shuffle=True,            # Mezclar datos en cada √©poca (importante para training)\n",
    "    num_workers=0            # Procesos paralelos (0 = todo en el principal)\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset_val,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,           # No mezclar en validaci√≥n (queremos resultados consistentes)\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "print(\"‚úÖ DataLoaders creados:\")\n",
    "print(f\"   - Train: {len(train_loader)} batches de {BATCH_SIZE} muestras\")\n",
    "print(f\"   - Validaci√≥n: {len(val_loader)} batches de {BATCH_SIZE} muestras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# VERIFICACI√ìN: VISUALIZAR UN BATCH\n",
    "# ============================================================\n",
    "\n",
    "# Obtenemos un batch de ejemplo\n",
    "# iter() crea un iterador, next() obtiene el siguiente elemento\n",
    "imagenes_ejemplo, etiquetas_ejemplo = next(iter(train_loader))\n",
    "\n",
    "print(\"üì¶ Verificaci√≥n del batch:\")\n",
    "print(f\"   - Shape de im√°genes: {imagenes_ejemplo.shape}\")\n",
    "print(f\"     (batch_size, canales, alto, ancho)\")\n",
    "print(f\"   - Shape de etiquetas: {etiquetas_ejemplo.shape}\")\n",
    "print(f\"   - Tipo de datos: {imagenes_ejemplo.dtype}\")\n",
    "print(f\"   - Rango de valores: [{imagenes_ejemplo.min():.3f}, {imagenes_ejemplo.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Configuraci√≥n del Modelo ResNet-50\n",
    "\n",
    "### ¬øQu√© es Transfer Learning?\n",
    "En lugar de entrenar una red desde cero (lo cual requiere millones de im√°genes), **reutilizamos** una red ya entrenada en ImageNet (1.2 millones de im√°genes, 1000 clases).\n",
    "\n",
    "### Estrategia:\n",
    "1. **Cargar** ResNet-50 con pesos de ImageNet\n",
    "2. **Congelar** las capas iniciales (ya aprendieron caracter√≠sticas generales)\n",
    "3. **Reemplazar** la √∫ltima capa para 50 clases (en lugar de 1000)\n",
    "4. **Entrenar** solo las capas finales con nuestros datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CARGAR RESNET-50 PRE-ENTRENADO\n",
    "# ============================================================\n",
    "\n",
    "# N√∫mero de clases en ESC-50\n",
    "NUM_CLASES = 50\n",
    "\n",
    "# Cargamos ResNet-50 con pesos pre-entrenados de ImageNet\n",
    "# weights='IMAGENET1K_V2' usa los mejores pesos disponibles\n",
    "print(\"‚¨áÔ∏è  Cargando modelo ResNet-50 pre-entrenado...\")\n",
    "\n",
    "# Creamos el modelo con pesos de ImageNet\n",
    "modelo = models.resnet50(weights='IMAGENET1K_V2')\n",
    "\n",
    "print(\"‚úÖ Modelo cargado\")\n",
    "\n",
    "# Veamos la estructura del modelo\n",
    "print(\"\\nüìê Estructura de ResNet-50 (√∫ltimas capas):\")\n",
    "print(f\"   Capa final original: {modelo.fc}\")\n",
    "print(f\"   (Dise√±ada para 1000 clases de ImageNet)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CONGELAR CAPAS Y MODIFICAR CAPA FINAL\n",
    "# ============================================================\n",
    "\n",
    "# --- Paso 1: Congelar todas las capas ---\n",
    "# \"Congelar\" significa que los pesos no se actualizar√°n durante el entrenamiento\n",
    "# Esto preserva el conocimiento aprendido de ImageNet\n",
    "\n",
    "for param in modelo.parameters():  # Iteramos sobre todos los par√°metros\n",
    "    param.requires_grad = False    # requires_grad=False = no entrenar este par√°metro\n",
    "\n",
    "print(\"‚ùÑÔ∏è  Todas las capas congeladas (pesos de ImageNet preservados)\")\n",
    "\n",
    "# --- Paso 2: Reemplazar la capa final (fc = fully connected) ---\n",
    "# La capa original tiene 1000 salidas (clases de ImageNet)\n",
    "# Necesitamos 50 salidas (clases de ESC-50)\n",
    "\n",
    "# Obtenemos el n√∫mero de caracter√≠sticas de entrada de la capa fc\n",
    "# in_features es el tama√±o del vector que entra a la capa\n",
    "num_features_entrada = modelo.fc.in_features\n",
    "print(f\"\\nüìä Features de entrada a la capa final: {num_features_entrada}\")\n",
    "\n",
    "# Creamos una nueva capa fully connected\n",
    "# nn.Linear(entrada, salida) crea una capa densa\n",
    "# Esta capa S√ç se entrenar√° (por defecto requires_grad=True)\n",
    "modelo.fc = nn.Sequential(\n",
    "    nn.Dropout(0.5),                           # Dropout para regularizaci√≥n (50% de neuronas apagadas)\n",
    "    nn.Linear(num_features_entrada, 512),      # Capa oculta: 2048 -> 512\n",
    "    nn.ReLU(),                                 # Activaci√≥n ReLU\n",
    "    nn.Dropout(0.3),                           # Otro Dropout (30%)\n",
    "    nn.Linear(512, NUM_CLASES)                 # Capa de salida: 512 -> 50 clases\n",
    ")\n",
    "\n",
    "print(f\"\\nüîß Nueva capa final creada:\")\n",
    "print(f\"   {modelo.fc}\")\n",
    "\n",
    "# --- Paso 3: Mover modelo al dispositivo (GPU/CPU) ---\n",
    "modelo = modelo.to(device)\n",
    "print(f\"\\nüñ•Ô∏è  Modelo movido a: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CONTAR PAR√ÅMETROS DEL MODELO\n",
    "# ============================================================\n",
    "\n",
    "# Contamos par√°metros totales y entrenables\n",
    "total_params = sum(p.numel() for p in modelo.parameters())  # numel = n√∫mero de elementos\n",
    "trainable_params = sum(p.numel() for p in modelo.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"üìä PAR√ÅMETROS DEL MODELO:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"   Total de par√°metros: {total_params:,}\")\n",
    "print(f\"   Par√°metros entrenables: {trainable_params:,}\")\n",
    "print(f\"   Par√°metros congelados: {total_params - trainable_params:,}\")\n",
    "print(f\"\\n   Porcentaje entrenable: {trainable_params/total_params*100:.2f}%\")\n",
    "print(\"\\nüí° Solo entrenamos ~4% del modelo (transfer learning eficiente)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Configuraci√≥n del Entrenamiento\n",
    "\n",
    "Definimos:\n",
    "- **Funci√≥n de p√©rdida**: CrossEntropyLoss (est√°ndar para clasificaci√≥n)\n",
    "- **Optimizador**: Adam (adaptativo, funciona bien en la mayor√≠a de casos)\n",
    "- **Learning Rate**: 0.001 (tasa de aprendizaje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# FUNCI√ìN DE P√âRDIDA Y OPTIMIZADOR\n",
    "# ============================================================\n",
    "\n",
    "# --- Funci√≥n de P√©rdida ---\n",
    "# CrossEntropyLoss combina LogSoftmax + NLLLoss\n",
    "# Es la funci√≥n est√°ndar para clasificaci√≥n multiclase\n",
    "# Mide qu√© tan \"equivocadas\" est√°n las predicciones\n",
    "criterio = nn.CrossEntropyLoss()\n",
    "\n",
    "# --- Optimizador ---\n",
    "# Adam es un optimizador que adapta el learning rate para cada par√°metro\n",
    "# Solo optimizamos los par√°metros que requieren gradiente (la capa final)\n",
    "# filter() selecciona solo los par√°metros con requires_grad=True\n",
    "optimizador = optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, modelo.parameters()),  # Solo par√°metros entrenables\n",
    "    lr=0.001,            # Learning rate (tasa de aprendizaje)\n",
    "    weight_decay=1e-4    # Regularizaci√≥n L2 para evitar overfitting\n",
    ")\n",
    "\n",
    "# --- Learning Rate Scheduler ---\n",
    "# Reduce el learning rate cuando la p√©rdida deja de mejorar\n",
    "# Esto ayuda a \"afinar\" el modelo en las √∫ltimas √©pocas\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizador,         # Optimizador a controlar\n",
    "    mode='min',          # Reducir cuando la m√©trica disminuye\n",
    "    factor=0.5,          # Multiplicar lr por 0.5 cuando se reduce\n",
    "    patience=3,          # Esperar 3 √©pocas sin mejora antes de reducir\n",
    "    verbose=True         # Mostrar mensaje cuando se reduce\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Configuraci√≥n del entrenamiento:\")\n",
    "print(f\"   - Funci√≥n de p√©rdida: CrossEntropyLoss\")\n",
    "print(f\"   - Optimizador: Adam (lr=0.001, weight_decay=1e-4)\")\n",
    "print(f\"   - Scheduler: ReduceLROnPlateau (factor=0.5, patience=3)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Funciones de Entrenamiento y Evaluaci√≥n\n",
    "\n",
    "Definimos las funciones que ejecutan una √©poca de entrenamiento y evaluaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# FUNCI√ìN DE ENTRENAMIENTO (UNA √âPOCA)\n",
    "# ============================================================\n",
    "\n",
    "def entrenar_una_epoca(modelo, dataloader, criterio, optimizador, device):\n",
    "    \"\"\"\n",
    "    Entrena el modelo durante una √©poca completa.\n",
    "    \n",
    "    Una √©poca = pasar por TODOS los datos de entrenamiento una vez.\n",
    "    \n",
    "    Par√°metros:\n",
    "    -----------\n",
    "    modelo : nn.Module\n",
    "        El modelo de PyTorch a entrenar\n",
    "    \n",
    "    dataloader : DataLoader\n",
    "        DataLoader con los datos de entrenamiento\n",
    "    \n",
    "    criterio : nn.Module\n",
    "        Funci√≥n de p√©rdida (CrossEntropyLoss)\n",
    "    \n",
    "    optimizador : optim.Optimizer\n",
    "        Optimizador (Adam)\n",
    "    \n",
    "    device : torch.device\n",
    "        Dispositivo (cuda o cpu)\n",
    "    \n",
    "    Retorna:\n",
    "    --------\n",
    "    tuple (float, float)\n",
    "        - P√©rdida promedio de la √©poca\n",
    "        - Accuracy (precisi√≥n) de la √©poca\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ponemos el modelo en modo entrenamiento\n",
    "    # Esto activa Dropout y BatchNorm en modo training\n",
    "    modelo.train()\n",
    "    \n",
    "    # Variables para acumular estad√≠sticas\n",
    "    perdida_total = 0.0      # Suma de todas las p√©rdidas\n",
    "    correctos = 0            # N√∫mero de predicciones correctas\n",
    "    total = 0                # N√∫mero total de muestras\n",
    "    \n",
    "    # Iteramos sobre todos los batches\n",
    "    # tqdm muestra una barra de progreso\n",
    "    for imagenes, etiquetas in tqdm(dataloader, desc=\"Entrenando\", leave=False):\n",
    "        \n",
    "        # --- Paso 1: Mover datos al dispositivo (GPU/CPU) ---\n",
    "        imagenes = imagenes.to(device)\n",
    "        etiquetas = etiquetas.to(device)\n",
    "        \n",
    "        # --- Paso 2: Forward pass ---\n",
    "        # Pasamos las im√°genes por el modelo para obtener predicciones\n",
    "        salidas = modelo(imagenes)\n",
    "        \n",
    "        # --- Paso 3: Calcular la p√©rdida ---\n",
    "        perdida = criterio(salidas, etiquetas)\n",
    "        \n",
    "        # --- Paso 4: Backward pass ---\n",
    "        # Primero, limpiamos los gradientes anteriores\n",
    "        optimizador.zero_grad()\n",
    "        \n",
    "        # Calculamos los gradientes (derivadas de la p√©rdida respecto a los pesos)\n",
    "        perdida.backward()\n",
    "        \n",
    "        # --- Paso 5: Actualizar pesos ---\n",
    "        # El optimizador ajusta los pesos usando los gradientes\n",
    "        optimizador.step()\n",
    "        \n",
    "        # --- Acumular estad√≠sticas ---\n",
    "        perdida_total += perdida.item() * imagenes.size(0)  # item() extrae el valor num√©rico\n",
    "        \n",
    "        # torch.max devuelve (valores_max, √≠ndices_max)\n",
    "        # Los √≠ndices son las clases predichas\n",
    "        _, predicciones = torch.max(salidas, 1)  # 1 = a lo largo de la dimensi√≥n de clases\n",
    "        \n",
    "        correctos += (predicciones == etiquetas).sum().item()  # Contamos aciertos\n",
    "        total += etiquetas.size(0)                              # Contamos muestras\n",
    "    \n",
    "    # Calculamos promedios\n",
    "    perdida_promedio = perdida_total / total\n",
    "    accuracy = correctos / total\n",
    "    \n",
    "    return perdida_promedio, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# FUNCI√ìN DE EVALUACI√ìN\n",
    "# ============================================================\n",
    "\n",
    "def evaluar(modelo, dataloader, criterio, device):\n",
    "    \"\"\"\n",
    "    Eval√∫a el modelo en un conjunto de datos (sin entrenar).\n",
    "    \n",
    "    Par√°metros:\n",
    "    -----------\n",
    "    modelo : nn.Module\n",
    "        El modelo de PyTorch a evaluar\n",
    "    \n",
    "    dataloader : DataLoader\n",
    "        DataLoader con los datos de evaluaci√≥n\n",
    "    \n",
    "    criterio : nn.Module\n",
    "        Funci√≥n de p√©rdida\n",
    "    \n",
    "    device : torch.device\n",
    "        Dispositivo (cuda o cpu)\n",
    "    \n",
    "    Retorna:\n",
    "    --------\n",
    "    tuple (float, float, list, list)\n",
    "        - P√©rdida promedio\n",
    "        - Accuracy\n",
    "        - Lista de todas las predicciones\n",
    "        - Lista de todas las etiquetas reales\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ponemos el modelo en modo evaluaci√≥n\n",
    "    # Esto desactiva Dropout y pone BatchNorm en modo inference\n",
    "    modelo.eval()\n",
    "    \n",
    "    perdida_total = 0.0\n",
    "    correctos = 0\n",
    "    total = 0\n",
    "    \n",
    "    # Listas para guardar predicciones y etiquetas (para m√©tricas detalladas)\n",
    "    todas_predicciones = []\n",
    "    todas_etiquetas = []\n",
    "    \n",
    "    # torch.no_grad() desactiva el c√°lculo de gradientes\n",
    "    # Esto ahorra memoria y acelera la evaluaci√≥n\n",
    "    with torch.no_grad():\n",
    "        for imagenes, etiquetas in tqdm(dataloader, desc=\"Evaluando\", leave=False):\n",
    "            \n",
    "            imagenes = imagenes.to(device)\n",
    "            etiquetas = etiquetas.to(device)\n",
    "            \n",
    "            # Forward pass (sin calcular gradientes)\n",
    "            salidas = modelo(imagenes)\n",
    "            \n",
    "            # Calcular p√©rdida\n",
    "            perdida = criterio(salidas, etiquetas)\n",
    "            \n",
    "            # Acumular estad√≠sticas\n",
    "            perdida_total += perdida.item() * imagenes.size(0)\n",
    "            \n",
    "            _, predicciones = torch.max(salidas, 1)\n",
    "            correctos += (predicciones == etiquetas).sum().item()\n",
    "            total += etiquetas.size(0)\n",
    "            \n",
    "            # Guardar para m√©tricas detalladas\n",
    "            # .cpu().numpy() mueve los tensores a CPU y los convierte a numpy\n",
    "            todas_predicciones.extend(predicciones.cpu().numpy())\n",
    "            todas_etiquetas.extend(etiquetas.cpu().numpy())\n",
    "    \n",
    "    perdida_promedio = perdida_total / total\n",
    "    accuracy = correctos / total\n",
    "    \n",
    "    return perdida_promedio, accuracy, todas_predicciones, todas_etiquetas\n",
    "\n",
    "print(\"‚úÖ Funciones de entrenamiento y evaluaci√≥n definidas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Bucle de Entrenamiento Principal\n",
    "\n",
    "Ahora entrenamos el modelo durante varias √©pocas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ENTRENAMIENTO DEL MODELO\n",
    "# ============================================================\n",
    "\n",
    "# N√∫mero de √©pocas (pasadas completas por los datos)\n",
    "# M√°s √©pocas = m√°s tiempo de entrenamiento, pero potencialmente mejor modelo\n",
    "NUM_EPOCAS = 15\n",
    "\n",
    "# Listas para guardar el historial de m√©tricas (para graficar)\n",
    "historial = {\n",
    "    'train_loss': [],      # P√©rdida de entrenamiento por √©poca\n",
    "    'train_acc': [],       # Accuracy de entrenamiento por √©poca\n",
    "    'val_loss': [],        # P√©rdida de validaci√≥n por √©poca\n",
    "    'val_acc': []          # Accuracy de validaci√≥n por √©poca\n",
    "}\n",
    "\n",
    "# Variable para guardar el mejor modelo\n",
    "mejor_accuracy = 0.0\n",
    "\n",
    "print(\"üöÄ INICIANDO ENTRENAMIENTO\")\n",
    "print(\"=\"*60)\n",
    "print(f\"   √âpocas: {NUM_EPOCAS}\")\n",
    "print(f\"   Batch size: {BATCH_SIZE}\")\n",
    "print(f\"   Dispositivo: {device}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Bucle principal de entrenamiento\n",
    "for epoca in range(NUM_EPOCAS):\n",
    "    print(f\"\\nüìÖ √âpoca {epoca+1}/{NUM_EPOCAS}\")\n",
    "    print(\"-\"*40)\n",
    "    \n",
    "    # --- Fase de Entrenamiento ---\n",
    "    train_loss, train_acc = entrenar_una_epoca(\n",
    "        modelo, train_loader, criterio, optimizador, device\n",
    "    )\n",
    "    \n",
    "    # --- Fase de Validaci√≥n ---\n",
    "    val_loss, val_acc, _, _ = evaluar(\n",
    "        modelo, val_loader, criterio, device\n",
    "    )\n",
    "    \n",
    "    # --- Guardar historial ---\n",
    "    historial['train_loss'].append(train_loss)\n",
    "    historial['train_acc'].append(train_acc)\n",
    "    historial['val_loss'].append(val_loss)\n",
    "    historial['val_acc'].append(val_acc)\n",
    "    \n",
    "    # --- Actualizar Learning Rate ---\n",
    "    # El scheduler reduce el lr si la p√©rdida no mejora\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # --- Mostrar resultados ---\n",
    "    print(f\"   Train Loss: {train_loss:.4f} | Train Acc: {train_acc*100:.2f}%\")\n",
    "    print(f\"   Val Loss:   {val_loss:.4f} | Val Acc:   {val_acc*100:.2f}%\")\n",
    "    \n",
    "    # --- Guardar mejor modelo ---\n",
    "    if val_acc > mejor_accuracy:\n",
    "        mejor_accuracy = val_acc\n",
    "        # torch.save guarda el modelo a un archivo\n",
    "        torch.save(modelo.state_dict(), 'mejor_modelo_esc50.pth')\n",
    "        print(f\"   üíæ Nuevo mejor modelo guardado! (Acc: {val_acc*100:.2f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"üèÜ ENTRENAMIENTO COMPLETADO\")\n",
    "print(f\"   Mejor accuracy de validaci√≥n: {mejor_accuracy*100:.2f}%\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 11. Visualizaci√≥n de Resultados\n",
    "\n",
    "Graficamos las curvas de aprendizaje para analizar el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# GR√ÅFICAS DE CURVAS DE APRENDIZAJE\n",
    "# ============================================================\n",
    "\n",
    "# Creamos una figura con 2 subplots lado a lado\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Eje X: n√∫mero de √©pocas\n",
    "epocas = range(1, len(historial['train_loss']) + 1)\n",
    "\n",
    "# --- Gr√°fica 1: P√©rdida (Loss) ---\n",
    "axes[0].plot(epocas, historial['train_loss'], 'b-o', label='Train Loss', linewidth=2)\n",
    "axes[0].plot(epocas, historial['val_loss'], 'r-o', label='Val Loss', linewidth=2)\n",
    "axes[0].set_xlabel('√âpoca', fontsize=12)\n",
    "axes[0].set_ylabel('P√©rdida (Loss)', fontsize=12)\n",
    "axes[0].set_title('Curva de P√©rdida', fontsize=14)\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3)  # Cuadr√≠cula semitransparente\n",
    "\n",
    "# --- Gr√°fica 2: Accuracy ---\n",
    "# Multiplicamos por 100 para mostrar como porcentaje\n",
    "axes[1].plot(epocas, [acc*100 for acc in historial['train_acc']], 'b-o', \n",
    "             label='Train Accuracy', linewidth=2)\n",
    "axes[1].plot(epocas, [acc*100 for acc in historial['val_acc']], 'r-o', \n",
    "             label='Val Accuracy', linewidth=2)\n",
    "axes[1].set_xlabel('√âpoca', fontsize=12)\n",
    "axes[1].set_ylabel('Accuracy (%)', fontsize=12)\n",
    "axes[1].set_title('Curva de Accuracy', fontsize=14)\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('curvas_aprendizaje.png', dpi=150)  # Guardamos la figura\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Interpretaci√≥n:\")\n",
    "print(\"   - Si ambas curvas bajan juntas: El modelo est√° aprendiendo bien\")\n",
    "print(\"   - Si train baja pero val sube: Overfitting (memorizaci√≥n)\")\n",
    "print(\"   - Si ambas se estancan alto: Underfitting (modelo muy simple)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 12. Evaluaci√≥n Final y M√©tricas Detalladas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CARGAR EL MEJOR MODELO Y EVALUAR\n",
    "# ============================================================\n",
    "\n",
    "# Cargamos el mejor modelo guardado durante el entrenamiento\n",
    "# state_dict contiene los pesos del modelo\n",
    "modelo.load_state_dict(torch.load('mejor_modelo_esc50.pth'))\n",
    "\n",
    "# Evaluamos en el conjunto de validaci√≥n\n",
    "val_loss, val_acc, predicciones, etiquetas_reales = evaluar(\n",
    "    modelo, val_loader, criterio, device\n",
    ")\n",
    "\n",
    "print(\"üìä EVALUACI√ìN FINAL DEL MEJOR MODELO\")\n",
    "print(\"=\"*60)\n",
    "print(f\"   P√©rdida de validaci√≥n: {val_loss:.4f}\")\n",
    "print(f\"   Accuracy de validaci√≥n: {val_acc*100:.2f}%\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# REPORTE DE CLASIFICACI√ìN DETALLADO\n",
    "# ============================================================\n",
    "\n",
    "# Obtenemos los nombres de las categor√≠as\n",
    "nombres_categorias = dataset_train.categorias\n",
    "\n",
    "# classification_report genera un reporte con precision, recall, f1-score\n",
    "# - Precision: De los que predije como X, ¬øcu√°ntos realmente son X?\n",
    "# - Recall: De los que realmente son X, ¬øcu√°ntos predije correctamente?\n",
    "# - F1-score: Media arm√≥nica de precision y recall\n",
    "\n",
    "print(\"\\nüìã REPORTE DE CLASIFICACI√ìN (por categor√≠a):\")\n",
    "print(\"=\"*70)\n",
    "print(classification_report(\n",
    "    etiquetas_reales, \n",
    "    predicciones, \n",
    "    target_names=nombres_categorias,\n",
    "    zero_division=0  # Evita warnings si alguna clase no tiene predicciones\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# MATRIZ DE CONFUSI√ìN\n",
    "# ============================================================\n",
    "\n",
    "# La matriz de confusi√≥n muestra qu√© categor√≠as se confunden entre s√≠\n",
    "# Filas = clase real, Columnas = clase predicha\n",
    "# Diagonal = predicciones correctas\n",
    "\n",
    "# Calculamos la matriz\n",
    "cm = confusion_matrix(etiquetas_reales, predicciones)\n",
    "\n",
    "# Creamos una figura grande (50 clases es mucho)\n",
    "plt.figure(figsize=(20, 16))\n",
    "\n",
    "# Usamos imshow para visualizar la matriz como imagen\n",
    "plt.imshow(cm, interpolation='nearest', cmap='Blues')\n",
    "plt.title('Matriz de Confusi√≥n - ESC-50', fontsize=16)\n",
    "plt.colorbar()\n",
    "\n",
    "# Configuramos los ejes con nombres de categor√≠as\n",
    "tick_marks = np.arange(len(nombres_categorias))\n",
    "plt.xticks(tick_marks, nombres_categorias, rotation=90, fontsize=6)\n",
    "plt.yticks(tick_marks, nombres_categorias, fontsize=6)\n",
    "\n",
    "plt.xlabel('Predicci√≥n', fontsize=12)\n",
    "plt.ylabel('Clase Real', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('matriz_confusion.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Interpretaci√≥n de la Matriz de Confusi√≥n:\")\n",
    "print(\"   - Colores m√°s oscuros = m√°s predicciones\")\n",
    "print(\"   - Diagonal oscura = buenas predicciones\")\n",
    "print(\"   - Valores fuera de la diagonal = errores (confusiones)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 13. Ejemplo de Predicci√≥n con un Audio Nuevo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# FUNCI√ìN PARA PREDECIR UN AUDIO INDIVIDUAL\n",
    "# ============================================================\n",
    "\n",
    "def predecir_audio(ruta_audio, modelo, categorias, device):\n",
    "    \"\"\"\n",
    "    Predice la categor√≠a de un archivo de audio.\n",
    "    \n",
    "    Par√°metros:\n",
    "    -----------\n",
    "    ruta_audio : str\n",
    "        Ruta al archivo de audio\n",
    "    \n",
    "    modelo : nn.Module\n",
    "        Modelo entrenado\n",
    "    \n",
    "    categorias : list\n",
    "        Lista de nombres de categor√≠as\n",
    "    \n",
    "    device : torch.device\n",
    "        Dispositivo (cuda/cpu)\n",
    "    \n",
    "    Retorna:\n",
    "    --------\n",
    "    tuple (str, float, dict)\n",
    "        - Categor√≠a predicha\n",
    "        - Confianza (probabilidad)\n",
    "        - Diccionario con top-5 predicciones\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ponemos el modelo en modo evaluaci√≥n\n",
    "    modelo.eval()\n",
    "    \n",
    "    # Convertimos el audio a espectrograma\n",
    "    mel_spec = audio_a_mel_espectrograma(ruta_audio)\n",
    "    \n",
    "    # Normalizamos\n",
    "    mel_spec = (mel_spec - mel_spec.min()) / (mel_spec.max() - mel_spec.min() + 1e-8)\n",
    "    \n",
    "    # Convertimos a tensor y a√±adimos dimensiones\n",
    "    mel_spec = torch.tensor(mel_spec, dtype=torch.float32)\n",
    "    mel_spec = mel_spec.unsqueeze(0)  # A√±adir dimensi√≥n de canal\n",
    "    mel_spec = mel_spec.repeat(3, 1, 1)  # Replicar a 3 canales\n",
    "    \n",
    "    # Aplicamos las mismas transformaciones\n",
    "    mel_spec = transformaciones(mel_spec)\n",
    "    \n",
    "    # A√±adimos dimensi√≥n de batch: (C, H, W) -> (1, C, H, W)\n",
    "    mel_spec = mel_spec.unsqueeze(0)\n",
    "    \n",
    "    # Movemos al dispositivo\n",
    "    mel_spec = mel_spec.to(device)\n",
    "    \n",
    "    # Hacemos la predicci√≥n\n",
    "    with torch.no_grad():\n",
    "        salida = modelo(mel_spec)\n",
    "        \n",
    "        # Aplicamos softmax para obtener probabilidades\n",
    "        probabilidades = torch.nn.functional.softmax(salida, dim=1)\n",
    "        \n",
    "        # Obtenemos top-5 predicciones\n",
    "        top5_prob, top5_idx = torch.topk(probabilidades, 5)\n",
    "        \n",
    "    # Extraemos resultados\n",
    "    idx_predicho = top5_idx[0][0].item()\n",
    "    confianza = top5_prob[0][0].item()\n",
    "    \n",
    "    # Creamos diccionario con top-5\n",
    "    top5 = {}\n",
    "    for i in range(5):\n",
    "        idx = top5_idx[0][i].item()\n",
    "        prob = top5_prob[0][i].item()\n",
    "        top5[categorias[idx]] = prob\n",
    "    \n",
    "    return categorias[idx_predicho], confianza, top5\n",
    "\n",
    "print(\"‚úÖ Funci√≥n de predicci√≥n definida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DEMOSTRACI√ìN: PREDECIR ALGUNOS AUDIOS DEL DATASET\n",
    "# ============================================================\n",
    "\n",
    "# Tomamos 5 audios aleatorios del conjunto de validaci√≥n\n",
    "ejemplos_demo = df_val.sample(5, random_state=42)\n",
    "\n",
    "print(\"üéµ DEMOSTRACI√ìN DE PREDICCIONES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for _, fila in ejemplos_demo.iterrows():\n",
    "    ruta = os.path.join(audio_dir, fila['filename'])\n",
    "    categoria_real = fila['category']\n",
    "    \n",
    "    # Hacemos la predicci√≥n\n",
    "    prediccion, confianza, top5 = predecir_audio(\n",
    "        ruta, modelo, nombres_categorias, device\n",
    "    )\n",
    "    \n",
    "    # Mostramos resultados\n",
    "    acierto = \"‚úÖ\" if prediccion == categoria_real else \"‚ùå\"\n",
    "    \n",
    "    print(f\"\\nüìÅ Archivo: {fila['filename']}\")\n",
    "    print(f\"   Real: {categoria_real}\")\n",
    "    print(f\"   Predicho: {prediccion} (confianza: {confianza*100:.1f}%) {acierto}\")\n",
    "    print(f\"   Top-3:\")\n",
    "    for i, (cat, prob) in enumerate(list(top5.items())[:3], 1):\n",
    "        print(f\"      {i}. {cat}: {prob*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 14. Guardar el Modelo Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# GUARDAR MODELO COMPLETO PARA USO FUTURO\n",
    "# ============================================================\n",
    "\n",
    "# Guardamos todo lo necesario para usar el modelo despu√©s\n",
    "checkpoint = {\n",
    "    'modelo_state_dict': modelo.state_dict(),  # Pesos del modelo\n",
    "    'categorias': nombres_categorias,           # Lista de categor√≠as\n",
    "    'accuracy': mejor_accuracy,                 # Accuracy alcanzado\n",
    "    'historial': historial                      # Historial de entrenamiento\n",
    "}\n",
    "\n",
    "torch.save(checkpoint, 'modelo_esc50_completo.pth')\n",
    "\n",
    "print(\"üíæ MODELO GUARDADO EXITOSAMENTE\")\n",
    "print(\"=\"*60)\n",
    "print(\"   Archivo: modelo_esc50_completo.pth\")\n",
    "print(f\"   Accuracy: {mejor_accuracy*100:.2f}%\")\n",
    "print(f\"   Categor√≠as: {len(nombres_categorias)}\")\n",
    "print(\"\\n   Para cargar el modelo en el futuro:\")\n",
    "print(\"   >>> checkpoint = torch.load('modelo_esc50_completo.pth')\")\n",
    "print(\"   >>> modelo.load_state_dict(checkpoint['modelo_state_dict'])\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 15. Conclusiones y Pr√≥ximos Pasos\n",
    "\n",
    "### Resumen\n",
    "Hemos construido un clasificador de sonidos ambientales que:\n",
    "1. **Convierte audio a im√°genes** (espectrogramas)\n",
    "2. **Usa transfer learning** de ResNet-50 (ImageNet)\n",
    "3. **Clasifica 50 categor√≠as** de sonidos\n",
    "\n",
    "### Posibles Mejoras\n",
    "- **Data Augmentation**: A√±adir ruido, cambiar pitch, time stretching\n",
    "- **Fine-tuning completo**: Descongelar m√°s capas de ResNet\n",
    "- **Otros modelos**: VGG, EfficientNet, Vision Transformer\n",
    "- **Validaci√≥n cruzada**: Usar los 5 folds para evaluaci√≥n m√°s robusta\n",
    "- **Ensemble**: Combinar m√∫ltiples modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# RESUMEN FINAL\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ ¬°PR√ÅCTICA COMPLETADA CON √âXITO!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nüìä RESUMEN:\")\n",
    "print(f\"   - Dataset: ESC-50 (2000 audios, 50 clases)\")\n",
    "print(f\"   - Modelo: ResNet-50 (transfer learning de ImageNet)\")\n",
    "print(f\"   - Accuracy final: {mejor_accuracy*100:.2f}%\")\n",
    "print(f\"   - √âpocas entrenadas: {NUM_EPOCAS}\")\n",
    "print(\"\\nüìÅ ARCHIVOS GENERADOS:\")\n",
    "print(\"   - mejor_modelo_esc50.pth (pesos del mejor modelo)\")\n",
    "print(\"   - modelo_esc50_completo.pth (checkpoint completo)\")\n",
    "print(\"   - curvas_aprendizaje.png (gr√°ficas de entrenamiento)\")\n",
    "print(\"   - matriz_confusion.png (matriz de confusi√≥n)\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
