{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Reinforcement Learning - Parte 2: Deep RL\n\n**Prerequisitos**: Haber completado `reinforcement_learning_clase.ipynb` (Parte 1)\n\n## Serie Completa\n\n| Notebook | Contenido | Estado |\n|----------|-----------|--------|\n| `reinforcement_learning_clase.ipynb` | Fundamentos, SARSA, Q-Learning | âœ… Completado |\n| **`reinforcement_learning_dqn.ipynb`** (este) | DQN, Gymnasium, PrÃ¡ctica | â—„ EstÃ¡s aquÃ­ |\n| `reinforcement_learning_clase2.ipynb` | Stable-Baselines3, PPO, SAC | Siguiente |\n\n---\n\n## Ãndice de este Notebook\n\n8. [Deep Q-Network (DQN)](#8-dqn) - Q-Learning + Redes Neuronales\n9. [Gymnasium: Entornos de RL](#9-gymnasium) - Entornos estÃ¡ndar\n10. [PrÃ¡ctica Final](#10-practica) - ImplementaciÃ³n completa\n\n## Â¿Por quÃ© separar?\n\nLa **Parte 1** cubre RL tabular donde:\n- Estados son discretos y finitos\n- Q(s,a) se almacena en una tabla/diccionario\n- No se necesitan redes neuronales\n\nLa **Parte 2** (este notebook) introduce Deep RL donde:\n- Estados pueden ser continuos o de alta dimensionalidad\n- Q(s,a) se aproxima con una red neuronal\n- Se requiere PyTorch\n\n---"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Imports necesarios para Deep RL\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from collections import defaultdict, deque\n",
    "\n",
    "# Deep Learning\n",
    "try:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.optim as optim\n",
    "    TORCH_AVAILABLE = True\n",
    "    print(f'PyTorch {torch.__version__} disponible')\n",
    "except ImportError:\n",
    "    TORCH_AVAILABLE = False\n",
    "    print('PyTorch no disponible. Instalar con: pip install torch')\n",
    "\n",
    "# Gymnasium\n",
    "try:\n",
    "    import gymnasium as gym\n",
    "    print(f'Gymnasium {gym.__version__} disponible')\n",
    "except ImportError:\n",
    "    print('Gymnasium no disponible. Instalar con: pip install gymnasium')\n",
    "\n",
    "# ConfiguraciÃ³n de visualizaciÃ³n\n",
    "plt.rcParams['figure.figsize'] = [10, 6]\n",
    "plt.rcParams['figure.dpi'] = 100"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='8-dqn'></a>\n",
    "# 8. Deep Q-Network (DQN)\n",
    "\n",
    "DQN fue el algoritmo que revolucionÃ³ el RL moderno. En 2015, DeepMind demostrÃ³ que podÃ­a aprender a jugar juegos de Atari **a nivel humano o superior**, usando solo los pÃ­xeles de la pantalla como entrada.\n",
    "\n",
    "## El Problema de las Tablas Q\n",
    "\n",
    "Q-Learning tabular funciona bien para problemas pequeÃ±os, pero tiene limitaciones severas:\n",
    "\n",
    "| Problema | Estados Posibles | Â¿Tabla Q viable? |\n",
    "|----------|------------------|------------------|\n",
    "| GridWorld 4x4 | 16 | âœ… SÃ­ |\n",
    "| Taxi (Gymnasium) | 500 | âœ… SÃ­ |\n",
    "| CartPole | âˆ (estados continuos) | âŒ No |\n",
    "| Atari (pÃ­xeles) | 256^(210Ã—160Ã—3) â‰ˆ 10^millions | âŒ Imposible |\n",
    "| Ajedrez | ~10^47 | âŒ Imposible |\n",
    "| Go | ~10^170 | âŒ RidÃ­culamente imposible |\n",
    "\n",
    "### El Problema de la DiscretizaciÃ³n\n",
    "\n",
    "Una \"soluciÃ³n\" para estados continuos es discretizar:\n",
    "```python\n",
    "# CartPole tiene 4 variables continuas\n",
    "# Si discretizamos cada una en 10 bins:\n",
    "estados = 10 * 10 * 10 * 10 = 10,000  # Manejable, pero...\n",
    "\n",
    "# Si usamos 100 bins para mÃ¡s precisiÃ³n:\n",
    "estados = 100^4 = 100,000,000  # Â¡100 millones!\n",
    "```\n",
    "\n",
    "**La maldiciÃ³n de la dimensionalidad**: El nÃºmero de estados crece exponencialmente con las dimensiones.\n",
    "\n",
    "---\n",
    "\n",
    "## La SoluciÃ³n: AproximaciÃ³n de Funciones\n",
    "\n",
    "En lugar de una tabla, usamos una **funciÃ³n** que aproxima Q(s, a):\n",
    "\n",
    "```\n",
    "TABLA Q (discreta)              RED NEURONAL (continua)\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ Estado â”‚ Q(s,a0) â”‚..â”‚         â”‚      s = [x, v, Î¸, Ï‰]       â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”¤         â”‚            â†“                â”‚\n",
    "â”‚ s=1    â”‚  2.3    â”‚..â”‚   â†’â†’â†’   â”‚     [Red Neuronal]          â”‚\n",
    "â”‚ s=2    â”‚  1.8    â”‚..â”‚         â”‚            â†“                â”‚\n",
    "â”‚ ...    â”‚  ...    â”‚..â”‚         â”‚ Q(s,a0), Q(s,a1), Q(s,a2)   â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### Ventajas de usar redes neuronales:\n",
    "\n",
    "1. **GeneralizaciÃ³n**: Estados similares tienen Q-valores similares\n",
    "2. **Compacto**: Millones de estados en miles de parÃ¡metros\n",
    "3. **Estados continuos**: Funciona directamente, sin discretizar\n",
    "4. **Representaciones ricas**: Puede aprender features automÃ¡ticamente\n",
    "\n",
    "---\n",
    "\n",
    "## Arquitectura DQN\n",
    "\n",
    "```\n",
    "      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "      â”‚                                                         â”‚\n",
    "      â”‚  Estado s                Capas Ocultas       Q-valores  â”‚\n",
    "      â”‚  â”Œâ”€â”€â”€â”                   â”Œâ”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”  â”‚\n",
    "      â”‚  â”‚ x â”‚â”€â”€â”€â”€â”€â”€â”            â”‚    â”‚ â”‚    â”‚   â”Œâ”€â”€â–¶â”‚Q(s,aâ‚€)â”‚  â”‚\n",
    "      â”‚  â”‚ v â”‚â”€â”€â”€â”€â”€â”€â”¼â”€â–¶ [64] â”€â”€â–¶â”‚ 64 â”‚â–¶â”‚ 64 â”‚â”€â”€â”¼â”€â”€â–¶â”‚Q(s,aâ‚)â”‚  â”‚\n",
    "      â”‚  â”‚ Î¸ â”‚â”€â”€â”€â”€â”€â”€â”˜    ReLU    â”‚ReLUâ”‚ â”‚ReLUâ”‚   â””â”€â”€â–¶â”‚Q(s,aâ‚‚)â”‚  â”‚\n",
    "      â”‚  â”‚ Ï‰ â”‚                   â””â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚\n",
    "      â”‚  â””â”€â”€â”€â”˜                                                  â”‚\n",
    "      â”‚  input                                        output    â”‚\n",
    "      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "      \n",
    "      Mejor acciÃ³n = argmax(Q(s, a))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## El Problema: Inestabilidad del Entrenamiento\n",
    "\n",
    "Usar redes neuronales con Q-Learning \"ingenuo\" no funciona bien:\n",
    "\n",
    "### Problema 1: CorrelaciÃ³n de Muestras\n",
    "- Las transiciones consecutivas (s, a, r, s') estÃ¡n muy correlacionadas\n",
    "- La red ve datos muy similares una y otra vez\n",
    "- Esto causa sobreajuste y olvido\n",
    "\n",
    "### Problema 2: Target MÃ³vil\n",
    "- Usamos Q(s', a') para calcular el target\n",
    "- Pero Â¡estamos cambiando la misma red que da esos targets!\n",
    "- Es como perseguir tu propia sombra\n",
    "\n",
    "---\n",
    "\n",
    "## Las Innovaciones de DQN (DeepMind, 2015)\n",
    "\n",
    "### 1. Experience Replay (Replay Buffer)\n",
    "\n",
    "**Idea**: Guardar transiciones en una memoria y samplear aleatoriamente.\n",
    "\n",
    "```python\n",
    "# En lugar de entrenar con la Ãºltima transiciÃ³n:\n",
    "entrenar(s, a, r, s')  # âŒ Muy correlacionado\n",
    "\n",
    "# Guardamos en un buffer y sampleamos:\n",
    "buffer.guardar(s, a, r, s')\n",
    "batch = buffer.sample(32)  # âœ… Muestras aleatorias, decorreladas\n",
    "entrenar(batch)\n",
    "```\n",
    "\n",
    "**Beneficios**:\n",
    "- Rompe la correlaciÃ³n temporal\n",
    "- Reutiliza experiencias (eficiencia de datos)\n",
    "- Suaviza la distribuciÃ³n de entrenamiento\n",
    "\n",
    "### 2. Target Network (Red Objetivo)\n",
    "\n",
    "**Idea**: Usar una copia \"congelada\" de la red para calcular targets.\n",
    "\n",
    "```python\n",
    "# Red Q principal (se actualiza cada paso)\n",
    "Q_principal(s, a)\n",
    "\n",
    "# Red Target (copia, se actualiza cada N pasos)\n",
    "Q_target(s', a')  # Usada para calcular el target\n",
    "\n",
    "# Cada N pasos:\n",
    "Q_target.copiar_pesos_de(Q_principal)\n",
    "```\n",
    "\n",
    "**Beneficios**:\n",
    "- Targets estables durante N pasos\n",
    "- Reduce oscilaciones\n",
    "- Permite convergencia\n",
    "\n",
    "---\n",
    "\n",
    "## Algoritmo DQN Completo\n",
    "\n",
    "```\n",
    "1. Inicializar red Q con pesos Î¸\n",
    "2. Inicializar red target Q_target con pesos Î¸_target = Î¸\n",
    "3. Inicializar replay buffer vacÃ­o\n",
    "\n",
    "4. Para cada episodio:\n",
    "    a. s = estado_inicial\n",
    "    \n",
    "    b. Mientras no termine:\n",
    "        i.   Elegir a con Îµ-greedy sobre Q(s; Î¸)\n",
    "        ii.  Ejecutar a, observar r, s'\n",
    "        iii. Guardar (s, a, r, s', done) en buffer\n",
    "        iv.  Samplear minibatch del buffer\n",
    "        v.   Para cada (sáµ¢, aáµ¢, ráµ¢, s'áµ¢, doneáµ¢) en batch:\n",
    "             - Si done: target = ráµ¢\n",
    "             - Si no:   target = ráµ¢ + Î³ max Q_target(s'áµ¢, a'; Î¸_target)\n",
    "        vi.  Actualizar Î¸ minimizando (Q(sáµ¢,aáµ¢;Î¸) - target)Â²\n",
    "        vii. s = s'\n",
    "    \n",
    "    c. Cada C pasos: Î¸_target â† Î¸\n",
    "\n",
    "5. Reducir Îµ gradualmente\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Mejoras Posteriores a DQN\n",
    "\n",
    "| Algoritmo | Mejora | Beneficio |\n",
    "|-----------|--------|-----------|\n",
    "| **Double DQN** | Usa Q principal para seleccionar, Q target para evaluar | Reduce sobreestimaciÃ³n |\n",
    "| **Dueling DQN** | Separa V(s) y A(s,a) en la arquitectura | Mejor en estados donde la acciÃ³n no importa |\n",
    "| **Prioritized Replay** | Samplea mÃ¡s las transiciones con alto TD error | Aprende mÃ¡s de experiencias \"sorprendentes\" |\n",
    "| **Rainbow** | Combina todas las mejoras | Estado del arte en Atari |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T15:43:23.626785Z",
     "iopub.status.busy": "2026-02-09T15:43:23.626785Z",
     "iopub.status.idle": "2026-02-09T15:43:27.712184Z",
     "shell.execute_reply": "2026-02-09T15:43:27.712184Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… PyTorch disponible\n",
      "\n",
      "ğŸ“‹ Componentes DQN:\n",
      "   - ReplayBuffer: Almacena experiencias pasadas\n",
      "   - DQN: Red neuronal que aproxima Q(s,a)\n",
      "   - AgenteDQN: Integra todo para aprender\n"
     ]
    }
   ],
   "source": [
    "# EJEMPLO PRÃCTICO 9: DQN Simple\n",
    "# ================================\n",
    "# Deep Q-Network: Q-Learning + Redes Neuronales\n",
    "# Permite manejar estados continuos o de alta dimensionalidad.\n",
    "\n",
    "# Verificar si PyTorch estÃ¡ disponible\n",
    "try:\n",
    "    import torch              # Framework de deep learning\n",
    "    import torch.nn as nn     # MÃ³dulo de redes neuronales\n",
    "    import torch.optim as optim  # Optimizadores (Adam, SGD, etc.)\n",
    "    TORCH_AVAILABLE = True\n",
    "    print(\"âœ… PyTorch disponible\")\n",
    "except ImportError:\n",
    "    TORCH_AVAILABLE = False\n",
    "    print(\"âš ï¸ PyTorch no estÃ¡ instalado. Ejecuta: pip install torch\")\n",
    "    print(\"   Las celdas de DQN no funcionarÃ¡n sin PyTorch.\")\n",
    "\n",
    "from collections import deque  # Cola de doble extremo (eficiente para buffers)\n",
    "\n",
    "if TORCH_AVAILABLE:\n",
    "\n",
    "    class ReplayBuffer:\n",
    "        \"\"\"\n",
    "        Buffer de experiencias para Experience Replay.\n",
    "\n",
    "        Â¿Por quÃ© Experience Replay?\n",
    "        1. ROMPE CORRELACIÃ“N: Las experiencias consecutivas estÃ¡n correlacionadas\n",
    "           (estado t+1 depende de t). Muestrear al azar rompe esta correlaciÃ³n.\n",
    "        2. REUTILIZA DATOS: Cada experiencia se puede usar mÃºltiples veces.\n",
    "        3. ESTABILIDAD: El entrenamiento es mÃ¡s estable con batches diversos.\n",
    "        \"\"\"\n",
    "\n",
    "        def __init__(self, capacidad=10000):\n",
    "            \"\"\"\n",
    "            Args:\n",
    "                capacidad: MÃ¡ximo de experiencias a almacenar.\n",
    "                           Cuando se llena, las mÃ¡s antiguas se descartan.\n",
    "            \"\"\"\n",
    "            # deque con maxlen descarta automÃ¡ticamente elementos antiguos\n",
    "            self.buffer = deque(maxlen=capacidad)\n",
    "\n",
    "        def agregar(self, estado, accion, recompensa, siguiente_estado, terminado):\n",
    "            \"\"\"\n",
    "            Guarda una transiciÃ³n (s, a, r, s', done) en el buffer.\n",
    "\n",
    "            Args:\n",
    "                estado: Estado donde se tomÃ³ la acciÃ³n\n",
    "                accion: AcciÃ³n ejecutada\n",
    "                recompensa: Recompensa recibida\n",
    "                siguiente_estado: Estado resultante\n",
    "                terminado: Si el episodio terminÃ³\n",
    "            \"\"\"\n",
    "            # Guardar la tupla completa\n",
    "            self.buffer.append((estado, accion, recompensa, siguiente_estado, terminado))\n",
    "\n",
    "        def sample(self, batch_size):\n",
    "            \"\"\"\n",
    "            Muestrea un batch aleatorio de experiencias.\n",
    "\n",
    "            Args:\n",
    "                batch_size: NÃºmero de experiencias a muestrear\n",
    "\n",
    "            Returns:\n",
    "                Tupla de arrays: (estados, acciones, recompensas, siguientes, terminados)\n",
    "            \"\"\"\n",
    "            # random.sample elige sin repeticiÃ³n\n",
    "            batch = random.sample(self.buffer, batch_size)\n",
    "\n",
    "            # Desempaquetar: convertir lista de tuplas a tuplas de listas\n",
    "            estados, acciones, recompensas, siguientes, terminados = zip(*batch)\n",
    "\n",
    "            # Convertir a arrays numpy para eficiencia\n",
    "            return (np.array(estados), np.array(acciones), np.array(recompensas),\n",
    "                    np.array(siguientes), np.array(terminados))\n",
    "\n",
    "        def __len__(self):\n",
    "            \"\"\"Devuelve el nÃºmero de experiencias almacenadas.\"\"\"\n",
    "            return len(self.buffer)\n",
    "\n",
    "\n",
    "    class DQN(nn.Module):\n",
    "        \"\"\"\n",
    "        Red neuronal que aproxima la funciÃ³n Q(s, a).\n",
    "\n",
    "        Arquitectura:\n",
    "        Input (estado) â†’ Capa 1 (64) â†’ ReLU â†’ Capa 2 (64) â†’ ReLU â†’ Output (Q-valores)\n",
    "\n",
    "        En lugar de una tabla Q[s][a], usamos una red que:\n",
    "        - Recibe: vector de estado (ej: [posiciÃ³n_x, posiciÃ³n_y])\n",
    "        - Devuelve: Q-valor para cada acciÃ³n [Q(s,a0), Q(s,a1), Q(s,a2), Q(s,a3)]\n",
    "        \"\"\"\n",
    "\n",
    "        def __init__(self, input_size, n_acciones):\n",
    "            \"\"\"\n",
    "            Args:\n",
    "                input_size: DimensiÃ³n del vector de estado\n",
    "                n_acciones: NÃºmero de acciones posibles\n",
    "            \"\"\"\n",
    "            super(DQN, self).__init__()  # Inicializar clase padre\n",
    "\n",
    "            # Definir la arquitectura como secuencia de capas\n",
    "            self.red = nn.Sequential(\n",
    "                # Capa 1: entrada â†’ 64 neuronas\n",
    "                nn.Linear(input_size, 64),\n",
    "                nn.ReLU(),  # ActivaciÃ³n no lineal\n",
    "\n",
    "                # Capa 2: 64 â†’ 64 neuronas\n",
    "                nn.Linear(64, 64),\n",
    "                nn.ReLU(),\n",
    "\n",
    "                # Capa de salida: 64 â†’ n_acciones\n",
    "                # Cada salida es el Q-valor de una acciÃ³n\n",
    "                nn.Linear(64, n_acciones)\n",
    "                # Sin activaciÃ³n: Q-valores pueden ser negativos\n",
    "            )\n",
    "\n",
    "        def forward(self, x):\n",
    "            \"\"\"\n",
    "            PropagaciÃ³n hacia adelante.\n",
    "\n",
    "            Args:\n",
    "                x: Tensor de estados (batch_size, input_size)\n",
    "\n",
    "            Returns:\n",
    "                Q-valores para cada acciÃ³n (batch_size, n_acciones)\n",
    "            \"\"\"\n",
    "            return self.red(x)\n",
    "\n",
    "\n",
    "    class AgenteDQN:\n",
    "        \"\"\"\n",
    "        Agente DQN completo con Experience Replay y Target Network.\n",
    "\n",
    "        Componentes clave:\n",
    "        1. Q-Network: Red que aprende (se actualiza cada paso)\n",
    "        2. Target Network: Copia de Q que se actualiza periÃ³dicamente\n",
    "        3. Replay Buffer: Almacena experiencias para muestreo aleatorio\n",
    "        \"\"\"\n",
    "\n",
    "        def __init__(self, input_size, n_acciones, lr=0.001, gamma=0.99, epsilon=1.0):\n",
    "            \"\"\"\n",
    "            Args:\n",
    "                input_size: DimensiÃ³n del estado\n",
    "                n_acciones: NÃºmero de acciones posibles\n",
    "                lr: Learning rate para el optimizador\n",
    "                gamma: Factor de descuento\n",
    "                epsilon: Probabilidad inicial de exploraciÃ³n\n",
    "            \"\"\"\n",
    "            self.n_acciones = n_acciones\n",
    "            self.gamma = gamma           # Factor de descuento\n",
    "            self.epsilon = epsilon       # ExploraciÃ³n inicial (100%)\n",
    "            self.epsilon_min = 0.01      # ExploraciÃ³n mÃ­nima (1%)\n",
    "            self.epsilon_decay = 0.995   # Factor de decaimiento\n",
    "\n",
    "            # RED Q (la que aprende)\n",
    "            self.q_network = DQN(input_size, n_acciones)\n",
    "\n",
    "            # RED TARGET (para estabilidad)\n",
    "            # Se inicializa igual a Q y se actualiza periÃ³dicamente\n",
    "            self.target_network = DQN(input_size, n_acciones)\n",
    "            self.target_network.load_state_dict(self.q_network.state_dict())\n",
    "\n",
    "            # OPTIMIZADOR: Adam es estÃ¡ndar para deep learning\n",
    "            self.optimizer = optim.Adam(self.q_network.parameters(), lr=lr)\n",
    "\n",
    "            # FUNCIÃ“N DE PÃ‰RDIDA: MSE entre Q predicho y target\n",
    "            self.loss_fn = nn.MSELoss()\n",
    "\n",
    "            # REPLAY BUFFER\n",
    "            self.memory = ReplayBuffer()\n",
    "\n",
    "        def estado_a_tensor(self, estado):\n",
    "            \"\"\"\n",
    "            Convierte el estado (tupla) a tensor de PyTorch.\n",
    "\n",
    "            Args:\n",
    "                estado: Tupla (fila, columna)\n",
    "\n",
    "            Returns:\n",
    "                Tensor normalizado [0, 1]\n",
    "            \"\"\"\n",
    "            # Normalizar coordenadas a rango [0, 1]\n",
    "            # Esto ayuda a la red a aprender mÃ¡s rÃ¡pido\n",
    "            return torch.FloatTensor([estado[0]/3, estado[1]/3])\n",
    "\n",
    "        def seleccionar_accion(self, estado):\n",
    "            \"\"\"\n",
    "            Selecciona acciÃ³n usando polÃ­tica Îµ-greedy.\n",
    "\n",
    "            Args:\n",
    "                estado: Estado actual\n",
    "\n",
    "            Returns:\n",
    "                Ãndice de la acciÃ³n seleccionada\n",
    "            \"\"\"\n",
    "            # Explorar con probabilidad epsilon\n",
    "            if random.random() < self.epsilon:\n",
    "                return random.randint(0, self.n_acciones - 1)\n",
    "\n",
    "            # Explotar: usar la red para elegir la mejor acciÃ³n\n",
    "            with torch.no_grad():  # No calcular gradientes (solo inferencia)\n",
    "                estado_tensor = self.estado_a_tensor(estado).unsqueeze(0)\n",
    "                q_valores = self.q_network(estado_tensor)\n",
    "                return q_valores.argmax().item()  # Ãndice del mÃ¡ximo\n",
    "\n",
    "        def recordar(self, estado, accion, recompensa, siguiente_estado, terminado):\n",
    "            \"\"\"Guarda experiencia en el replay buffer.\"\"\"\n",
    "            self.memory.agregar(estado, accion, recompensa, siguiente_estado, terminado)\n",
    "\n",
    "        def entrenar(self, batch_size=32):\n",
    "            \"\"\"\n",
    "            Entrena la red Q con un batch del replay buffer.\n",
    "\n",
    "            Este es el nÃºcleo del algoritmo DQN.\n",
    "\n",
    "            Args:\n",
    "                batch_size: NÃºmero de experiencias para entrenar\n",
    "\n",
    "            Returns:\n",
    "                loss: PÃ©rdida del entrenamiento (para monitoreo)\n",
    "            \"\"\"\n",
    "            # No entrenar si no hay suficientes experiencias\n",
    "            if len(self.memory) < batch_size:\n",
    "                return 0\n",
    "\n",
    "            # PASO 1: Muestrear batch aleatorio del buffer\n",
    "            estados, acciones, recompensas, siguientes, terminados = self.memory.sample(batch_size)\n",
    "\n",
    "            # PASO 2: Convertir a tensores de PyTorch\n",
    "            estados_t = torch.FloatTensor([[s[0]/3, s[1]/3] for s in estados])\n",
    "            acciones_t = torch.LongTensor(acciones)\n",
    "            recompensas_t = torch.FloatTensor(recompensas)\n",
    "            siguientes_t = torch.FloatTensor([[s[0]/3, s[1]/3] for s in siguientes])\n",
    "            terminados_t = torch.FloatTensor(terminados)\n",
    "\n",
    "            # PASO 3: Calcular Q-valores actuales para las acciones tomadas\n",
    "            # q_network(estados) devuelve Q para todas las acciones\n",
    "            # gather selecciona solo las Q de las acciones que se tomaron\n",
    "            q_actuales = self.q_network(estados_t).gather(1, acciones_t.unsqueeze(1))\n",
    "\n",
    "            # PASO 4: Calcular targets usando la TARGET network\n",
    "            # Esta es la clave de DQN: usar red separada para estabilidad\n",
    "            with torch.no_grad():\n",
    "                # MÃ¡ximo Q del siguiente estado (segÃºn target network)\n",
    "                q_siguientes = self.target_network(siguientes_t).max(1)[0]\n",
    "                # Si terminÃ³, no hay futuro\n",
    "                q_siguientes = q_siguientes * (1 - terminados_t)\n",
    "                # Target = r + Î³ * max Q(s', a')\n",
    "                targets = recompensas_t + self.gamma * q_siguientes\n",
    "\n",
    "            # PASO 5: Calcular pÃ©rdida (diferencia entre predicciÃ³n y target)\n",
    "            loss = self.loss_fn(q_actuales.squeeze(), targets)\n",
    "\n",
    "            # PASO 6: Backpropagation\n",
    "            self.optimizer.zero_grad()  # Limpiar gradientes anteriores\n",
    "            loss.backward()             # Calcular gradientes\n",
    "            self.optimizer.step()       # Actualizar pesos\n",
    "\n",
    "            return loss.item()\n",
    "\n",
    "        def actualizar_target(self):\n",
    "            \"\"\"\n",
    "            Copia los pesos de q_network a target_network.\n",
    "\n",
    "            Se hace periÃ³dicamente (cada N episodios) para estabilidad.\n",
    "            \"\"\"\n",
    "            self.target_network.load_state_dict(self.q_network.state_dict())\n",
    "\n",
    "        def decaer_epsilon(self):\n",
    "            \"\"\"Reduce epsilon gradualmente (explorar menos con el tiempo).\"\"\"\n",
    "            self.epsilon = max(self.epsilon_min, self.epsilon * self.epsilon_decay)\n",
    "\n",
    "\n",
    "    print(\"\\nâœ… Clases DQN definidas correctamente\")\n",
    "    print(\"   - ReplayBuffer: Almacena experiencias\")\n",
    "    print(\"   - DQN: Red neuronal para Q-valores\")\n",
    "    print(\"   - AgenteDQN: Agente completo con entrenamiento\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T15:43:27.715200Z",
     "iopub.status.busy": "2026-02-09T15:43:27.713695Z",
     "iopub.status.idle": "2026-02-09T15:43:42.416723Z",
     "shell.execute_reply": "2026-02-09T15:43:42.416227Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ENTRENAMIENTO DQN\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodio   0 | Recompensa: -100.0 | Promedio: -100.00 | Îµ: 0.995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodio  50 | Recompensa:   -8.0 | Promedio: -22.16 | Îµ: 0.774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodio 100 | Recompensa:   -2.0 | Promedio:  -8.68 | Îµ: 0.603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodio 150 | Recompensa:    4.0 | Promedio:  -1.20 | Îµ: 0.469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodio 200 | Recompensa:    4.0 | Promedio:   1.40 | Îµ: 0.365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodio 250 | Recompensa:    4.0 | Promedio:   2.24 | Îµ: 0.284\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š DQN entrenado exitosamente\n",
      "Recompensa promedio final: 3.28\n"
     ]
    }
   ],
   "source": [
    "# EJEMPLO PRÃCTICO 10: Entrenar DQN en GridWorld\n",
    "\n",
    "if not TORCH_AVAILABLE:\n",
    "    print(\"âš ï¸ PyTorch no disponible. Salta esta celda.\")\n",
    "else:\n",
    "    def entrenar_dqn(env, n_episodios=300):\n",
    "        \"\"\"Entrena un agente DQN\"\"\"\n",
    "        agente = AgenteDQN(input_size=2, n_acciones=4)\n",
    "        \n",
    "        recompensas_historial = []\n",
    "        perdidas_historial = []\n",
    "        \n",
    "        for episodio in range(n_episodios):\n",
    "            estado = env.reset()\n",
    "            recompensa_total = 0\n",
    "            perdida_total = 0\n",
    "            pasos = 0\n",
    "            \n",
    "            for _ in range(100):\n",
    "                accion = agente.seleccionar_accion(estado)\n",
    "                siguiente, recompensa, terminado = env.step(accion)\n",
    "                \n",
    "                agente.recordar(estado, accion, recompensa, siguiente, terminado)\n",
    "                perdida = agente.entrenar(batch_size=32)\n",
    "                \n",
    "                recompensa_total += recompensa\n",
    "                perdida_total += perdida\n",
    "                pasos += 1\n",
    "                estado = siguiente\n",
    "                \n",
    "                if terminado:\n",
    "                    break\n",
    "            \n",
    "            # Actualizar target network cada 10 episodios\n",
    "            if episodio % 10 == 0:\n",
    "                agente.actualizar_target()\n",
    "            \n",
    "            agente.decay_epsilon()\n",
    "            \n",
    "            recompensas_historial.append(recompensa_total)\n",
    "            perdidas_historial.append(perdida_total / max(pasos, 1))\n",
    "            \n",
    "            if episodio % 50 == 0:\n",
    "                promedio = np.mean(recompensas_historial[-50:]) if len(recompensas_historial) >= 50 else np.mean(recompensas_historial)\n",
    "                print(f\"Episodio {episodio:3d} | Recompensa: {recompensa_total:6.1f} | \"\n",
    "                      f\"Promedio: {promedio:6.2f} | Îµ: {agente.epsilon:.3f}\")\n",
    "        \n",
    "        return agente, recompensas_historial, perdidas_historial\n",
    "\n",
    "\n",
    "    # Entrenar\n",
    "    print(\"=\" * 60)\n",
    "    print(\"ENTRENAMIENTO DQN\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    env = GridWorld()\n",
    "    agente_dqn, recompensas_dqn, perdidas_dqn = entrenar_dqn(env, n_episodios=300)\n",
    "\n",
    "    # Visualizar\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "    window = 20\n",
    "    recompensas_suav = np.convolve(recompensas_dqn, np.ones(window)/window, mode='valid')\n",
    "\n",
    "    axes[0].plot(recompensas_suav)\n",
    "    axes[0].set_xlabel('Episodio')\n",
    "    axes[0].set_ylabel('Recompensa (media mÃ³vil)')\n",
    "    axes[0].set_title('Curva de Aprendizaje DQN')\n",
    "\n",
    "    axes[1].plot(perdidas_dqn, color='red', alpha=0.5)\n",
    "    axes[1].set_xlabel('Episodio')\n",
    "    axes[1].set_ylabel('PÃ©rdida (Loss)')\n",
    "    axes[1].set_title('PÃ©rdida durante Entrenamiento')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"\\nğŸ“Š DQN entrenado exitosamente\")\n",
    "    print(f\"Recompensa promedio final: {np.mean(recompensas_dqn[-50:]):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='9-gymnasium'></a>\n",
    "# 9. Gymnasium: Entornos de RL\n",
    "\n",
    "## Â¿QuÃ© es Gymnasium?\n",
    "\n",
    "**Gymnasium** (antes OpenAI Gym) es la librerÃ­a estÃ¡ndar para crear y usar entornos de RL. Piensa en ella como el \"framework de testing\" del RL.\n",
    "\n",
    "### Â¿Por quÃ© necesitamos Gymnasium?\n",
    "\n",
    "1. **EstandarizaciÃ³n**: Todos los entornos tienen la misma interfaz\n",
    "2. **Reproducibilidad**: FÃ¡cil comparar algoritmos en los mismos entornos\n",
    "3. **Benchmarks**: Entornos clÃ¡sicos para medir el progreso\n",
    "4. **Comunidad**: Miles de entornos disponibles\n",
    "\n",
    "### Entornos Populares\n",
    "\n",
    "| CategorÃ­a | Entornos | DescripciÃ³n |\n",
    "|-----------|----------|-------------|\n",
    "| **Control ClÃ¡sico** | CartPole, MountainCar, Pendulum, Acrobot | Problemas de fÃ­sica simples, ideales para empezar |\n",
    "| **Box2D** | LunarLander, BipedalWalker, CarRacing | FÃ­sica 2D mÃ¡s realista |\n",
    "| **Atari** | Breakout, Pong, Space Invaders, 50+ juegos | Videojuegos clÃ¡sicos |\n",
    "| **MuJoCo** | Ant, Humanoid, HalfCheetah | RobÃ³tica 3D de alta fidelidad |\n",
    "| **Toy Text** | FrozenLake, Taxi, Blackjack | Entornos de texto para debugging |\n",
    "\n",
    "---\n",
    "\n",
    "## Gymnasium y la TeorÃ­a de RL\n",
    "\n",
    "Cada componente de Gymnasium implementa un concepto teÃ³rico del framework de RL:\n",
    "\n",
    "```\n",
    "TEORÃA (MDP)                         GYMNASIUM (CÃ³digo)\n",
    "============                         ==================\n",
    "\n",
    "    Entorno E                    â†â†’  env = gym.make(\"...\")\n",
    "        â†“                                    â†“\n",
    "    Espacio de Estados S         â†â†’  env.observation_space\n",
    "    Espacio de Acciones A        â†â†’  env.action_space\n",
    "        â†“                                    â†“\n",
    "    Estado inicial sâ‚€            â†â†’  obs, info = env.reset()\n",
    "        â†“                                    â†“\n",
    "    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "    â”‚ Paso temporal t â”‚              â”‚ obs, r, term, trunc, _  â”‚\n",
    "    â”‚                 â”‚         â†â†’   â”‚   = env.step(action)    â”‚\n",
    "    â”‚ P(s'|s,a): s'   â”‚              â”‚                         â”‚\n",
    "    â”‚ R(s,a): r       â”‚              â”‚ obs = s', r = reward    â”‚\n",
    "    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "        â†“                                    â†“\n",
    "    Estado terminal              â†â†’  terminated = True\n",
    "    Horizonte T (lÃ­mite)         â†â†’  truncated = True\n",
    "```\n",
    "\n",
    "### Tabla de Correspondencias\n",
    "\n",
    "| Concepto TeÃ³rico | SÃ­mbolo | Gymnasium | Ejemplo |\n",
    "|------------------|---------|-----------|---------|\n",
    "| Entorno | E | `env` | `gym.make(\"CartPole-v1\")` |\n",
    "| Espacio de estados | S | `env.observation_space` | `Box(4,)` = 4 valores continuos |\n",
    "| Espacio de acciones | A | `env.action_space` | `Discrete(2)` = 2 acciones |\n",
    "| Estado actual | s | `observation` | `[0.02, 0.5, -0.01, -0.3]` |\n",
    "| AcciÃ³n | a | `action` | `0` o `1` |\n",
    "| FunciÃ³n de transiciÃ³n | P(s'\\|s,a) | `env.step()` â†’ `obs` | FÃ­sica del entorno |\n",
    "| FunciÃ³n de recompensa | R(s,a) | `env.step()` â†’ `reward` | `+1` por cada paso |\n",
    "| Estado terminal | s âˆˆ S_terminal | `terminated` | Poste cayÃ³ |\n",
    "| Horizonte finito | T | `truncated` | 500 pasos mÃ¡ximo |\n",
    "| Estado inicial | sâ‚€ | `env.reset()` | PosiciÃ³n inicial |\n",
    "| Factor descuento | Î³ | En tu agente | `gamma = 0.99` |\n",
    "| PolÃ­tica | Ï€(a\\|s) | Tu agente | `agent.select_action(obs)` |\n",
    "\n",
    "---\n",
    "\n",
    "## La API de Gymnasium\n",
    "\n",
    "### Ciclo BÃ¡sico\n",
    "\n",
    "```python\n",
    "import gymnasium as gym\n",
    "\n",
    "# 1. Crear el entorno\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "\n",
    "# 2. Reiniciar (obtener estado inicial)\n",
    "observation, info = env.reset()\n",
    "\n",
    "# 3. Bucle de interacciÃ³n\n",
    "for _ in range(1000):\n",
    "    action = env.action_space.sample()  # Tu agente elegirÃ­a aquÃ­\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "    if terminated or truncated:\n",
    "        observation, info = env.reset()\n",
    "\n",
    "# 4. Cerrar el entorno\n",
    "env.close()\n",
    "```\n",
    "\n",
    "### Componentes de la API\n",
    "\n",
    "| MÃ©todo/Atributo | DescripciÃ³n | Retorna |\n",
    "|-----------------|-------------|---------|\n",
    "| `env.reset()` | Reinicia el entorno | `(observation, info)` |\n",
    "| `env.step(action)` | Ejecuta una acciÃ³n | `(obs, reward, terminated, truncated, info)` |\n",
    "| `env.observation_space` | Describe el espacio de observaciones | `Box`, `Discrete`, etc. |\n",
    "| `env.action_space` | Describe el espacio de acciones | `Box`, `Discrete`, etc. |\n",
    "| `env.close()` | Libera recursos | None |\n",
    "\n",
    "### Terminated vs Truncated\n",
    "\n",
    "- **terminated**: El episodio terminÃ³ por razones del entorno (ej: el poste cayÃ³, llegaste a la meta)\n",
    "- **truncated**: El episodio terminÃ³ por lÃ­mite de tiempo (ej: mÃ¡ximo 500 pasos)\n",
    "\n",
    "```python\n",
    "done = terminated or truncated  # Para compatibilidad con cÃ³digo antiguo\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Espacios (Spaces)\n",
    "\n",
    "Los espacios definen quÃ© observaciones y acciones son vÃ¡lidas.\n",
    "\n",
    "### Tipos de Espacios\n",
    "\n",
    "| Tipo | DescripciÃ³n | Ejemplo |\n",
    "|------|-------------|---------|\n",
    "| `Discrete(n)` | Enteros de 0 a n-1 | Acciones: izq/der = `Discrete(2)` |\n",
    "| `Box(low, high, shape)` | Arreglo de floats | ObservaciÃ³n 4D: `Box(-inf, inf, (4,))` |\n",
    "| `MultiBinary(n)` | Array de 0s y 1s | Botones presionados: `MultiBinary(8)` |\n",
    "| `MultiDiscrete([n1, n2])` | MÃºltiples discretos | Joystick: `MultiDiscrete([3, 3])` |\n",
    "| `Dict({...})` | Diccionario de espacios | ObservaciÃ³n compleja |\n",
    "| `Tuple((s1, s2))` | Tupla de espacios | MÃºltiples sensores |\n",
    "\n",
    "### MÃ©todos Ãštiles de Espacios\n",
    "\n",
    "```python\n",
    "# Generar una muestra aleatoria vÃ¡lida\n",
    "action = env.action_space.sample()\n",
    "\n",
    "# Verificar si un valor estÃ¡ en el espacio\n",
    "is_valid = env.observation_space.contains(obs)\n",
    "\n",
    "# Obtener lÃ­mites (para Box)\n",
    "low = env.observation_space.low\n",
    "high = env.observation_space.high\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## VectorEnv: Entornos Paralelos\n",
    "\n",
    "Para entrenar mÃ¡s rÃ¡pido, puedes ejecutar **mÃºltiples entornos en paralelo**. Esto es esencial para algoritmos como PPO y A2C.\n",
    "\n",
    "### Â¿Por quÃ© usar VectorEnv?\n",
    "\n",
    "| Sin VectorEnv | Con VectorEnv |\n",
    "|---------------|---------------|\n",
    "| 1 entorno, 1 CPU | N entornos, N CPUs |\n",
    "| Recolecta 1 experiencia por step | Recolecta N experiencias por step |\n",
    "| Entrenamiento lento | Entrenamiento N veces mÃ¡s rÃ¡pido |\n",
    "\n",
    "### Tipos de VectorEnv\n",
    "\n",
    "```python\n",
    "from gymnasium.vector import SyncVectorEnv, AsyncVectorEnv\n",
    "\n",
    "# SyncVectorEnv: Todos los entornos avanzan juntos (mÃ¡s simple)\n",
    "envs = SyncVectorEnv([\n",
    "    lambda: gym.make(\"CartPole-v1\"),\n",
    "    lambda: gym.make(\"CartPole-v1\"),\n",
    "    lambda: gym.make(\"CartPole-v1\"),\n",
    "    lambda: gym.make(\"CartPole-v1\"),\n",
    "])  # 4 entornos en paralelo\n",
    "\n",
    "# AsyncVectorEnv: Cada entorno avanza independiente (mÃ¡s eficiente)\n",
    "envs = AsyncVectorEnv([\n",
    "    lambda: gym.make(\"CartPole-v1\") for _ in range(4)\n",
    "])\n",
    "```\n",
    "\n",
    "### Uso de VectorEnv\n",
    "\n",
    "```python\n",
    "# Reset devuelve array de observaciones (una por entorno)\n",
    "observations, infos = envs.reset()\n",
    "print(observations.shape)  # (4, 4) = 4 entornos Ã— 4 features\n",
    "\n",
    "# Step recibe array de acciones (una por entorno)\n",
    "actions = np.array([0, 1, 0, 1])  # AcciÃ³n para cada entorno\n",
    "observations, rewards, terminateds, truncateds, infos = envs.step(actions)\n",
    "\n",
    "# Los entornos que terminan se resetean automÃ¡ticamente\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Crear un Entorno Custom\n",
    "\n",
    "Puedes crear tus propios entornos siguiendo la interfaz de Gymnasium.\n",
    "\n",
    "### Estructura BÃ¡sica\n",
    "\n",
    "```python\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "\n",
    "class MiEntornoCustom(gym.Env):\n",
    "    \"\"\"Plantilla para crear un entorno personalizado.\"\"\"\n",
    "\n",
    "    metadata = {\"render_modes\": [\"human\", \"rgb_array\"]}\n",
    "\n",
    "    def __init__(self, render_mode=None):\n",
    "        super().__init__()\n",
    "\n",
    "        # DEFINIR ESPACIO DE ACCIONES\n",
    "        self.action_space = spaces.Discrete(4)  # 4 acciones\n",
    "\n",
    "        # DEFINIR ESPACIO DE OBSERVACIONES\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=np.array([0, 0]),\n",
    "            high=np.array([10, 10]),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "\n",
    "        self.state = None\n",
    "        self.render_mode = render_mode\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        \"\"\"Reinicia el entorno al estado inicial.\"\"\"\n",
    "        super().reset(seed=seed)\n",
    "\n",
    "        # Inicializar estado\n",
    "        self.state = self.np_random.uniform(low=0, high=10, size=(2,)).astype(np.float32)\n",
    "\n",
    "        return self.state, {}\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Ejecuta una acciÃ³n en el entorno.\"\"\"\n",
    "        # Aplicar acciÃ³n\n",
    "        moves = {0: [0, 1], 1: [1, 0], 2: [0, -1], 3: [-1, 0]}\n",
    "        self.state = np.clip(self.state + moves[action], 0, 10).astype(np.float32)\n",
    "\n",
    "        # Calcular recompensa\n",
    "        goal = np.array([10, 10])\n",
    "        distance = np.linalg.norm(self.state - goal)\n",
    "        reward = -distance\n",
    "\n",
    "        # Verificar si terminÃ³\n",
    "        terminated = distance < 0.5\n",
    "        if terminated:\n",
    "            reward += 100\n",
    "\n",
    "        return self.state, reward, terminated, False, {}\n",
    "\n",
    "    def render(self):\n",
    "        if self.render_mode == \"human\":\n",
    "            print(f\"PosiciÃ³n: {self.state}\")\n",
    "```\n",
    "\n",
    "### Registrar el Entorno\n",
    "\n",
    "```python\n",
    "from gymnasium.envs.registration import register\n",
    "\n",
    "register(\n",
    "    id=\"MiEntorno-v1\",\n",
    "    entry_point=\"mi_modulo:MiEntornoCustom\",\n",
    "    max_episode_steps=200,\n",
    ")\n",
    "\n",
    "# Ahora puedes usar: gym.make(\"MiEntorno-v1\")\n",
    "```\n",
    "\n",
    "### Checklist para Entornos Custom\n",
    "\n",
    "| Requisito | DescripciÃ³n |\n",
    "|-----------|-------------|\n",
    "| âœ… `action_space` | Definido en `__init__` |\n",
    "| âœ… `observation_space` | Definido en `__init__` |\n",
    "| âœ… `reset()` â†’ `(obs, info)` | Devuelve estado inicial vÃ¡lido |\n",
    "| âœ… `step(action)` â†’ 5 valores | `(obs, reward, terminated, truncated, info)` |\n",
    "\n",
    "---\n",
    "\n",
    "## Wrappers: Modificando Entornos\n",
    "\n",
    "Los wrappers modifican el comportamiento sin cambiar el cÃ³digo del entorno.\n",
    "\n",
    "### Wrappers Comunes\n",
    "\n",
    "```python\n",
    "from gymnasium.wrappers import TimeLimit, RecordVideo, NormalizeObservation, ClipReward\n",
    "\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "env = TimeLimit(env, max_episode_steps=200)\n",
    "env = RecordVideo(env, \"videos/\", episode_trigger=lambda x: x % 100 == 0)\n",
    "```\n",
    "\n",
    "### Wrappers y TeorÃ­a RL\n",
    "\n",
    "| Wrapper | Modifica | Concepto TeÃ³rico |\n",
    "|---------|----------|------------------|\n",
    "| `TimeLimit` | truncated | Horizonte T |\n",
    "| `ClipReward` | reward | FunciÃ³n R(s,a) |\n",
    "| `NormalizeObservation` | observation | Espacio S |\n",
    "| `FrameStack` | observation | Estado como historial |\n",
    "\n",
    "---\n",
    "\n",
    "## Renderizado\n",
    "\n",
    "```python\n",
    "# Render en tiempo real (abre ventana)\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
    "\n",
    "# Render como imagen RGB (para grabar)\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
    "frame = env.render()\n",
    "\n",
    "# Sin renderizado (mÃ¡s rÃ¡pido para entrenar)\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Reproducibilidad (Seeding)\n",
    "\n",
    "```python\n",
    "# Semilla al resetear (recomendado)\n",
    "observation, info = env.reset(seed=42)\n",
    "\n",
    "# Para VectorEnv\n",
    "observations, infos = envs.reset(seed=[42, 43, 44, 45])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T15:43:42.417716Z",
     "iopub.status.busy": "2026-02-09T15:43:42.417716Z",
     "iopub.status.idle": "2026-02-09T15:43:42.505491Z",
     "shell.execute_reply": "2026-02-09T15:43:42.505491Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXPLORANDO GYMNASIUM\n",
      "============================================================\n",
      "\n",
      "ğŸ“¦ Entorno: CartPole-v1\n",
      "----------------------------------------\n",
      "Espacio de observaciÃ³n: Box([-4.8               -inf -0.41887903        -inf], [4.8               inf 0.41887903        inf], (4,), float32)\n",
      "  - Tipo: Box\n",
      "  - Forma: (4,)\n",
      "  - LÃ­mites: [-4.8               -inf -0.41887903        -inf] a [4.8               inf 0.41887903        inf]\n",
      "\n",
      "Espacio de acciones: Discrete(2)\n",
      "  - NÃºmero de acciones: 2\n",
      "  - Acciones: 0 = empujar izquierda, 1 = empujar derecha\n",
      "\n",
      "ğŸ”„ DespuÃ©s de reset():\n",
      "  ObservaciÃ³n: [ 0.0273956  -0.00611216  0.03585979  0.0197368 ]\n",
      "  Info: {}\n",
      "\n",
      "âš¡ DespuÃ©s de step(0):\n",
      "  Nueva observaciÃ³n: [ 0.02727336 -0.20172954  0.03625453  0.32351476]\n",
      "  Recompensa: 1.0\n",
      "  Terminado: False\n",
      "  Truncado: False\n",
      "\n",
      "============================================================\n",
      "SIGNIFICADO DE LA OBSERVACIÃ“N EN CARTPOLE\n",
      "============================================================\n",
      "\n",
      "La observaciÃ³n es un vector de 4 valores:\n",
      "  [0] PosiciÃ³n del carro     (-4.8 a 4.8)\n",
      "  [1] Velocidad del carro    (-âˆ a âˆ)\n",
      "  [2] Ãngulo del poste       (-0.42 rad a 0.42 rad)\n",
      "  [3] Velocidad angular      (-âˆ a âˆ)\n",
      "\n",
      "Objetivo: Mantener el poste en equilibrio\n",
      "Recompensa: +1 por cada paso que el poste sigue en pie\n",
      "Termina cuando:\n",
      "  - El poste se inclina mÃ¡s de 12Â°\n",
      "  - El carro sale del lÃ­mite\n",
      "  - Se alcanzan 500 pasos (Ã©xito)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# EJEMPLO PRÃCTICO 11: Explorando Gymnasium\n",
    "\n",
    "# Instalar gymnasium si no estÃ¡ disponible\n",
    "try:\n",
    "    import gymnasium as gym\n",
    "except ModuleNotFoundError:\n",
    "    print(\"Instalando gymnasium...\")\n",
    "    !pip install gymnasium -q\n",
    "    import gymnasium as gym\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"EXPLORANDO GYMNASIUM\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Crear entorno CartPole\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "\n",
    "print(\"\\nğŸ“¦ Entorno: CartPole-v1\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Espacio de observaciÃ³n: {env.observation_space}\")\n",
    "print(f\"  - Tipo: {type(env.observation_space).__name__}\")\n",
    "print(f\"  - Forma: {env.observation_space.shape}\")\n",
    "print(f\"  - LÃ­mites: {env.observation_space.low} a {env.observation_space.high}\")\n",
    "\n",
    "print(f\"\\nEspacio de acciones: {env.action_space}\")\n",
    "print(f\"  - NÃºmero de acciones: {env.action_space.n}\")\n",
    "print(f\"  - Acciones: 0 = empujar izquierda, 1 = empujar derecha\")\n",
    "\n",
    "# Reset\n",
    "observacion, info = env.reset(seed=42)\n",
    "print(f\"\\nğŸ”„ DespuÃ©s de reset():\")\n",
    "print(f\"  ObservaciÃ³n: {observacion}\")\n",
    "print(f\"  Info: {info}\")\n",
    "\n",
    "# Un paso\n",
    "accion = env.action_space.sample()\n",
    "obs, reward, terminated, truncated, info = env.step(accion)\n",
    "\n",
    "print(f\"\\nâš¡ DespuÃ©s de step({accion}):\")\n",
    "print(f\"  Nueva observaciÃ³n: {obs}\")\n",
    "print(f\"  Recompensa: {reward}\")\n",
    "print(f\"  Terminado: {terminated}\")\n",
    "print(f\"  Truncado: {truncated}\")\n",
    "\n",
    "env.close()\n",
    "\n",
    "# Significado de la observaciÃ³n en CartPole\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SIGNIFICADO DE LA OBSERVACIÃ“N EN CARTPOLE\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\"\"\n",
    "La observaciÃ³n es un vector de 4 valores:\n",
    "  [0] PosiciÃ³n del carro     (-4.8 a 4.8)\n",
    "  [1] Velocidad del carro    (-âˆ a âˆ)\n",
    "  [2] Ãngulo del poste       (-0.42 rad a 0.42 rad)\n",
    "  [3] Velocidad angular      (-âˆ a âˆ)\n",
    "\n",
    "Objetivo: Mantener el poste en equilibrio\n",
    "Recompensa: +1 por cada paso que el poste sigue en pie\n",
    "Termina cuando:\n",
    "  - El poste se inclina mÃ¡s de 12Â°\n",
    "  - El carro sale del lÃ­mite\n",
    "  - Se alcanzan 500 pasos (Ã©xito)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T15:43:42.507003Z",
     "iopub.status.busy": "2026-02-09T15:43:42.507003Z",
     "iopub.status.idle": "2026-02-09T15:43:42.534378Z",
     "shell.execute_reply": "2026-02-09T15:43:42.534378Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ENTORNOS POPULARES DE GYMNASIUM\n",
      "======================================================================\n",
      "\n",
      "ğŸ“¦ CartPole-v1\n",
      "   Equilibrar un poste sobre un carro\n",
      "   Observaciones: Box([-4.8               -inf -0.41887903        -inf], [4.8               inf 0.41887903        inf], (4,), float32)\n",
      "   Acciones: Discrete(2)\n",
      "   Prueba aleatoria: 14 pasos, recompensa = 14.0\n",
      "\n",
      "ğŸ“¦ MountainCar-v0\n",
      "   Subir un coche a la cima de una montaÃ±a\n",
      "   Observaciones: Box([-1.2  -0.07], [0.6  0.07], (2,), float32)\n",
      "   Acciones: Discrete(3)\n",
      "   Prueba aleatoria: 200 pasos, recompensa = -200.0\n",
      "\n",
      "ğŸ“¦ Acrobot-v1\n",
      "   Balancear un brazo robÃ³tico hacia arriba\n",
      "   Observaciones: Box([ -1.        -1.        -1.        -1.       -12.566371 -28.274334], [ 1.        1.        1.        1.       12.566371 28.274334], (6,), float32)\n",
      "   Acciones: Discrete(3)\n",
      "   Prueba aleatoria: 200 pasos, recompensa = -200.0\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "ENTORNOS ADICIONALES (requieren instalaciÃ³n extra)\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "âŒ LunarLander-v3 - No instalado\n",
      "   Aterrizar una nave espacial (requiere: pip install gymnasium[box2d])\n",
      "\n",
      "======================================================================\n",
      "ğŸ’¡ Para instalar entornos adicionales:\n",
      "   pip install gymnasium[box2d]    # LunarLander, BipedalWalker\n",
      "   pip install gymnasium[atari]    # Juegos Atari\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# EJEMPLO PRÃCTICO 12: Probando diferentes entornos\n",
    "\n",
    "# Asegurarse de que gym estÃ¡ importado\n",
    "try:\n",
    "    gym\n",
    "except NameError:\n",
    "    import gymnasium as gym\n",
    "\n",
    "# Entornos que siempre estÃ¡n disponibles (sin dependencias extra)\n",
    "entornos_basicos = [\n",
    "    (\"CartPole-v1\", \"Equilibrar un poste sobre un carro\"),\n",
    "    (\"MountainCar-v0\", \"Subir un coche a la cima de una montaÃ±a\"),\n",
    "    (\"Acrobot-v1\", \"Balancear un brazo robÃ³tico hacia arriba\"),\n",
    "]\n",
    "\n",
    "# Entornos que requieren dependencias adicionales\n",
    "entornos_extra = [\n",
    "    (\"LunarLander-v3\", \"Aterrizar una nave espacial (requiere: pip install gymnasium[box2d])\"),\n",
    "]\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ENTORNOS POPULARES DE GYMNASIUM\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for nombre, descripcion in entornos_basicos:\n",
    "    try:\n",
    "        env = gym.make(nombre)\n",
    "        print(f\"\\nğŸ“¦ {nombre}\")\n",
    "        print(f\"   {descripcion}\")\n",
    "        print(f\"   Observaciones: {env.observation_space}\")\n",
    "        print(f\"   Acciones: {env.action_space}\")\n",
    "        \n",
    "        # Probar un episodio aleatorio\n",
    "        obs, _ = env.reset()\n",
    "        recompensa_total = 0\n",
    "        pasos = 0\n",
    "        \n",
    "        for _ in range(200):\n",
    "            accion = env.action_space.sample()\n",
    "            obs, recompensa, terminado, truncado, _ = env.step(accion)\n",
    "            recompensa_total += recompensa\n",
    "            pasos += 1\n",
    "            if terminado or truncado:\n",
    "                break\n",
    "        \n",
    "        print(f\"   Prueba aleatoria: {pasos} pasos, recompensa = {recompensa_total:.1f}\")\n",
    "        env.close()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâš ï¸ {nombre}: Error - {e}\")\n",
    "\n",
    "# Intentar entornos extra\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"ENTORNOS ADICIONALES (requieren instalaciÃ³n extra)\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for nombre, descripcion in entornos_extra:\n",
    "    try:\n",
    "        env = gym.make(nombre)\n",
    "        print(f\"\\nâœ… {nombre} - Disponible\")\n",
    "        print(f\"   {descripcion}\")\n",
    "        print(f\"   Observaciones: {env.observation_space}\")\n",
    "        print(f\"   Acciones: {env.action_space}\")\n",
    "        env.close()\n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ {nombre} - No instalado\")\n",
    "        print(f\"   {descripcion}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ğŸ’¡ Para instalar entornos adicionales:\")\n",
    "print(\"   pip install gymnasium[box2d]    # LunarLander, BipedalWalker\")\n",
    "print(\"   pip install gymnasium[atari]    # Juegos Atari\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='10-practica'></a>\n",
    "# 10. PrÃ¡ctica Final\n",
    "\n",
    "## Objetivo\n",
    "\n",
    "**Entrega un Jupyter Notebook donde cargues un environment de Gymnasium y entrenes un bot que aprenda a resolver la tarea.**\n",
    "\n",
    "---\n",
    "\n",
    "## Pasos Recomendados\n",
    "\n",
    "### Paso 1: Elegir un Entorno\n",
    "\n",
    "| Dificultad | Entorno | DescripciÃ³n | Algoritmo Recomendado |\n",
    "|------------|---------|-------------|----------------------|\n",
    "| â­ FÃ¡cil | `CartPole-v1` | Equilibrar un poste | Q-Learning (discretizado) o DQN |\n",
    "| â­ FÃ¡cil | `FrozenLake-v1` | Navegar en hielo | Q-Learning tabular |\n",
    "| â­â­ Media | `MountainCar-v0` | Subir una colina | DQN (recompensa sparse) |\n",
    "| â­â­ Media | `LunarLander-v3` | Aterrizar nave | DQN o PPO (requiere box2d) |\n",
    "| â­â­â­ DifÃ­cil | `Acrobot-v1` | Balancear robot | DQN con buen diseÃ±o |\n",
    "\n",
    "### Paso 2: Analizar el Entorno\n",
    "\n",
    "Antes de implementar nada, entiende tu entorno:\n",
    "\n",
    "```python\n",
    "import gymnasium as gym\n",
    "\n",
    "env = gym.make(\"TU_ENTORNO\")\n",
    "print(f\"Observaciones: {env.observation_space}\")\n",
    "print(f\"Acciones: {env.action_space}\")\n",
    "\n",
    "# Ejecuta varios episodios aleatorios para entender el problema\n",
    "obs, _ = env.reset()\n",
    "for _ in range(100):\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, term, trunc, info = env.step(action)\n",
    "    print(f\"Obs: {obs}, Reward: {reward}\")\n",
    "    if term or trunc:\n",
    "        break\n",
    "```\n",
    "\n",
    "**Preguntas a responder:**\n",
    "- Â¿CuÃ¡ntas dimensiones tiene la observaciÃ³n?\n",
    "- Â¿CuÃ¡ntas acciones hay?\n",
    "- Â¿CuÃ¡ndo termina un episodio?\n",
    "- Â¿CÃ³mo es la estructura de recompensas?\n",
    "\n",
    "### Paso 3: DiseÃ±ar el Agente\n",
    "\n",
    "Elige tu enfoque:\n",
    "\n",
    "| Enfoque | CuÃ¡ndo usarlo | Complejidad |\n",
    "|---------|---------------|-------------|\n",
    "| **Q-Learning Tabular** | Estados discretos (FrozenLake, Taxi) | Baja |\n",
    "| **Q-Learning + DiscretizaciÃ³n** | Estados continuos simples (CartPole) | Media |\n",
    "| **DQN** | Estados continuos, mÃ¡s dimensiones | Alta |\n",
    "| **Stable-Baselines3** | Cualquier entorno, sin implementar desde cero | Baja (usar librerÃ­a) |\n",
    "\n",
    "### Paso 4: Entrenar y Visualizar\n",
    "\n",
    "Tu notebook debe incluir:\n",
    "\n",
    "1. **Curva de aprendizaje**: Recompensa vs episodio\n",
    "2. **MÃ©tricas**: Recompensa promedio, desviaciÃ³n estÃ¡ndar\n",
    "3. **EvaluaciÃ³n final**: Ejecutar el agente entrenado sin exploraciÃ³n\n",
    "\n",
    "### Paso 5: Analizar Resultados\n",
    "\n",
    "Responde en tu notebook:\n",
    "- Â¿El agente aprendiÃ³? Â¿CÃ³mo lo sabes?\n",
    "- Â¿QuÃ© hiperparÃ¡metros probaste?\n",
    "- Â¿QuÃ© cambiarÃ­as para mejorarlo?\n",
    "\n",
    "---\n",
    "\n",
    "## Requisitos del Entregable\n",
    "\n",
    "| Requisito | Puntos | DescripciÃ³n |\n",
    "|-----------|--------|-------------|\n",
    "| CÃ³digo funcional | 30% | El notebook ejecuta sin errores y entrena un agente |\n",
    "| Curvas de aprendizaje | 20% | GrÃ¡fica que muestra mejora del agente |\n",
    "| EvaluaciÃ³n | 20% | Demostrar el agente final funcionando |\n",
    "| DocumentaciÃ³n | 20% | Explicar decisiones, hiperparÃ¡metros, resultados |\n",
    "| Creatividad | 10% | Entorno diferente, mejoras al algoritmo, anÃ¡lisis extra |\n",
    "\n",
    "---\n",
    "\n",
    "## OpciÃ³n A: ImplementaciÃ³n Desde Cero\n",
    "\n",
    "Si quieres entender los algoritmos a fondo, implementa tu propio agente.\n",
    "\n",
    "### Plantilla Q-Learning con DiscretizaciÃ³n (CartPole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T15:43:42.536397Z",
     "iopub.status.busy": "2026-02-09T15:43:42.534378Z",
     "iopub.status.idle": "2026-02-09T15:43:42.538703Z",
     "shell.execute_reply": "2026-02-09T15:43:42.538703Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LibrerÃ­as importadas correctamente\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# PRÃCTICA FINAL: REINFORCEMENT LEARNING\n",
    "# ============================================================\n",
    "# Nombre: [TU NOMBRE]\n",
    "# Fecha: [FECHA]\n",
    "# Entorno elegido: [NOMBRE DEL ENTORNO]\n",
    "# ============================================================\n",
    "\n",
    "# Imports necesarios (gymnasium ya deberÃ­a estar instalado)\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque, defaultdict\n",
    "import random\n",
    "\n",
    "# Opcional: Para DQN (descomenta si lo usas)\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "\n",
    "print(\"âœ… LibrerÃ­as importadas correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T15:43:42.538703Z",
     "iopub.status.busy": "2026-02-09T15:43:42.538703Z",
     "iopub.status.idle": "2026-02-09T15:43:42.543103Z",
     "shell.execute_reply": "2026-02-09T15:43:42.543103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "ANÃLISIS DEL ENTORNO\n",
      "==================================================\n",
      "Espacio de observaciÃ³n: Box([-4.8               -inf -0.41887903        -inf], [4.8               inf 0.41887903        inf], (4,), float32)\n",
      "Espacio de acciones: Discrete(2)\n"
     ]
    }
   ],
   "source": [
    "# PASO 1: Cargar y explorar el entorno\n",
    "# ============================================================\n",
    "\n",
    "# TODO: Elige tu entorno\n",
    "env = gym.make(\"CartPole-v1\")  # Cambia esto si quieres otro entorno\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"ANÃLISIS DEL ENTORNO\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# TODO: Analiza el espacio de estados y acciones\n",
    "print(f\"Espacio de observaciÃ³n: {env.observation_space}\")\n",
    "print(f\"Espacio de acciones: {env.action_space}\")\n",
    "\n",
    "# TODO: Describe quÃ© significa cada observaciÃ³n y acciÃ³n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T15:43:42.543103Z",
     "iopub.status.busy": "2026-02-09T15:43:42.543103Z",
     "iopub.status.idle": "2026-02-09T15:43:42.546457Z",
     "shell.execute_reply": "2026-02-09T15:43:42.546457Z"
    }
   },
   "outputs": [],
   "source": [
    "# PASO 2: Implementar el agente\n",
    "# ============================================================\n",
    "\n",
    "# TODO: Implementa tu agente aquÃ­\n",
    "# Puedes usar Q-Learning (con discretizaciÃ³n), DQN, o tu propio algoritmo\n",
    "\n",
    "class MiAgente:\n",
    "    def __init__(self, env):\n",
    "        # TODO: Inicializa tu agente\n",
    "        pass\n",
    "    \n",
    "    def seleccionar_accion(self, estado):\n",
    "        # TODO: Implementa la selecciÃ³n de acciÃ³n\n",
    "        pass\n",
    "    \n",
    "    def aprender(self, estado, accion, recompensa, siguiente_estado, terminado):\n",
    "        # TODO: Implementa el algoritmo de aprendizaje\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T15:43:42.547468Z",
     "iopub.status.busy": "2026-02-09T15:43:42.547468Z",
     "iopub.status.idle": "2026-02-09T15:43:42.551478Z",
     "shell.execute_reply": "2026-02-09T15:43:42.551209Z"
    }
   },
   "outputs": [],
   "source": [
    "# PASO 3: Entrenar el agente\n",
    "# ============================================================\n",
    "\n",
    "def entrenar(env, agente, n_episodios=500):\n",
    "    \"\"\"FunciÃ³n de entrenamiento\"\"\"\n",
    "    recompensas = []\n",
    "    \n",
    "    for episodio in range(n_episodios):\n",
    "        estado, _ = env.reset()\n",
    "        recompensa_total = 0\n",
    "        terminado = False\n",
    "        truncado = False\n",
    "        \n",
    "        while not (terminado or truncado):\n",
    "            # TODO: Completa el bucle de entrenamiento\n",
    "            accion = agente.seleccionar_accion(estado)\n",
    "            siguiente, recompensa, terminado, truncado, _ = env.step(accion)\n",
    "            \n",
    "            agente.aprender(estado, accion, recompensa, siguiente, terminado or truncado)\n",
    "            \n",
    "            estado = siguiente\n",
    "            recompensa_total += recompensa\n",
    "        \n",
    "        recompensas.append(recompensa_total)\n",
    "        \n",
    "        if episodio % 100 == 0:\n",
    "            print(f\"Episodio {episodio}: Recompensa = {recompensa_total:.1f}\")\n",
    "    \n",
    "    return recompensas\n",
    "\n",
    "# TODO: Entrena tu agente\n",
    "# agente = MiAgente(env)\n",
    "# recompensas = entrenar(env, agente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T15:43:42.552496Z",
     "iopub.status.busy": "2026-02-09T15:43:42.552496Z",
     "iopub.status.idle": "2026-02-09T15:43:42.554308Z",
     "shell.execute_reply": "2026-02-09T15:43:42.554308Z"
    }
   },
   "outputs": [],
   "source": [
    "# PASO 4: Visualizar resultados\n",
    "# ============================================================\n",
    "\n",
    "# TODO: Grafica las curvas de aprendizaje\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(recompensas)\n",
    "# plt.xlabel('Episodio')\n",
    "# plt.ylabel('Recompensa')\n",
    "# plt.title('Curva de Aprendizaje')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T15:43:42.554308Z",
     "iopub.status.busy": "2026-02-09T15:43:42.554308Z",
     "iopub.status.idle": "2026-02-09T15:43:42.558320Z",
     "shell.execute_reply": "2026-02-09T15:43:42.558320Z"
    }
   },
   "outputs": [],
   "source": [
    "# PASO 5: Evaluar el agente entrenado\n",
    "# ============================================================\n",
    "\n",
    "def evaluar(env, agente, n_episodios=10):\n",
    "    \"\"\"EvalÃºa el agente sin exploraciÃ³n\"\"\"\n",
    "    recompensas = []\n",
    "    \n",
    "    for _ in range(n_episodios):\n",
    "        estado, _ = env.reset()\n",
    "        recompensa_total = 0\n",
    "        terminado = False\n",
    "        truncado = False\n",
    "        \n",
    "        while not (terminado or truncado):\n",
    "            # TODO: EvalÃºa sin exploraciÃ³n (greedy)\n",
    "            accion = agente.seleccionar_accion(estado)  # Sin epsilon\n",
    "            estado, recompensa, terminado, truncado, _ = env.step(accion)\n",
    "            recompensa_total += recompensa\n",
    "        \n",
    "        recompensas.append(recompensa_total)\n",
    "    \n",
    "    print(f\"EvaluaciÃ³n: {np.mean(recompensas):.1f} Â± {np.std(recompensas):.1f}\")\n",
    "    return recompensas\n",
    "\n",
    "# TODO: EvalÃºa tu agente\n",
    "# evaluar(env, agente)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## OpciÃ³n B: Usando Stable-Baselines3 (Recomendado para principiantes)\n",
    "\n",
    "Si prefieres enfocarte en entender RL sin implementar algoritmos desde cero, usa Stable-Baselines3.\n",
    "\n",
    "### InstalaciÃ³n\n",
    "```bash\n",
    "pip install stable-baselines3\n",
    "```\n",
    "\n",
    "### Ejemplo Completo con PPO\n",
    "\n",
    "```python\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import gymnasium as gym\n",
    "\n",
    "# 1. Crear entorno\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "\n",
    "# 2. Crear agente\n",
    "model = PPO(\n",
    "    \"MlpPolicy\",        # PolÃ­tica con red neuronal\n",
    "    env,\n",
    "    learning_rate=0.0003,\n",
    "    gamma=0.99,\n",
    "    verbose=1           # Muestra progreso\n",
    ")\n",
    "\n",
    "# 3. Entrenar\n",
    "model.learn(total_timesteps=50_000)\n",
    "\n",
    "# 4. Evaluar\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=10)\n",
    "print(f\"Recompensa: {mean_reward:.2f} Â± {std_reward:.2f}\")\n",
    "\n",
    "# 5. Guardar modelo\n",
    "model.save(\"cartpole_ppo\")\n",
    "\n",
    "# 6. DemostraciÃ³n visual\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
    "obs, _ = env.reset()\n",
    "for _ in range(1000):\n",
    "    action, _ = model.predict(obs, deterministic=True)\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    if terminated or truncated:\n",
    "        obs, _ = env.reset()\n",
    "env.close()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Criterios de EvaluaciÃ³n\n",
    "\n",
    "| Criterio | Puntos |\n",
    "|----------|--------|\n",
    "| CÃ³digo funcional que entrena un agente | 30% |\n",
    "| Curvas de aprendizaje que muestran mejora | 20% |\n",
    "| EvaluaciÃ³n del agente entrenado | 20% |\n",
    "| DocumentaciÃ³n y explicaciones | 20% |\n",
    "| Creatividad (entorno diferente, mejoras al algoritmo) | 10% |\n",
    "\n",
    "---\n",
    "\n",
    "## Errores Comunes y CÃ³mo Evitarlos\n",
    "\n",
    "| Error | Causa | SoluciÃ³n |\n",
    "|-------|-------|----------|\n",
    "| El agente no mejora | Learning rate muy alto/bajo | Probar Î± = 0.001, 0.01, 0.1 |\n",
    "| Recompensa oscila mucho | Epsilon muy alto al final | Reducir Îµ gradualmente hasta 0.01 |\n",
    "| Se queda en Ã³ptimo local | Poca exploraciÃ³n inicial | Empezar con Îµ = 1.0 |\n",
    "| Olvida lo aprendido | Buffer muy pequeÃ±o (DQN) | Aumentar tamaÃ±o del buffer |\n",
    "| Entrenamiento muy lento | Renderizado activo | Quitar `render_mode=\"human\"` |\n",
    "\n",
    "---\n",
    "\n",
    "## Tips Finales\n",
    "\n",
    "1. **Empieza simple**: CartPole-v1 es perfecto para empezar\n",
    "2. **Loggea todo**: Guarda mÃ©tricas para analizar despuÃ©s\n",
    "3. **Usa semillas**: `env.reset(seed=42)` para reproducibilidad\n",
    "4. **Experimenta**: Cambia hiperparÃ¡metros y observa el efecto\n",
    "5. **No te rindas**: El RL es difÃ­cil, los agentes a veces tardan en aprender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Recursos Adicionales\n",
    "\n",
    "## Libros (de mÃ¡s accesible a mÃ¡s avanzado)\n",
    "\n",
    "| Libro | Autor | Nivel | Enlace |\n",
    "|-------|-------|-------|--------|\n",
    "| **Grokking Deep RL** | Miguel Morales | Principiante | Con cÃ³digo Python paso a paso |\n",
    "| **RL: An Introduction** | Sutton & Barto | Intermedio | [Gratis online](http://incompleteideas.net/book/the-book-2nd.html) - EL libro clÃ¡sico |\n",
    "| **Deep RL Hands-On** | Maxim Lapan | Avanzado | Implementaciones prÃ¡cticas con PyTorch |\n",
    "\n",
    "## Cursos Online (Gratuitos)\n",
    "\n",
    "| Curso | Plataforma | DescripciÃ³n |\n",
    "|-------|------------|-------------|\n",
    "| **Deep RL Course** | Hugging Face | El mejor curso prÃ¡ctico actual, con certificado |\n",
    "| **RL Specialization** | Coursera (Alberta) | Curso acadÃ©mico riguroso |\n",
    "| **Spinning Up** | OpenAI | DocumentaciÃ³n + cÃ³digo de referencia |\n",
    "| **RL Course** | DeepMind x UCL | Lecturas en YouTube por expertos de DeepMind |\n",
    "\n",
    "## LibrerÃ­as Principales\n",
    "\n",
    "| LibrerÃ­a | Uso | InstalaciÃ³n |\n",
    "|----------|-----|-------------|\n",
    "| **Gymnasium** | Entornos estÃ¡ndar | `pip install gymnasium` |\n",
    "| **Stable-Baselines3** | Algoritmos listos para usar | `pip install stable-baselines3` |\n",
    "| **RLlib** | RL escalable y distribuido | `pip install ray[rllib]` |\n",
    "| **CleanRL** | Implementaciones simples y claras | `pip install cleanrl` |\n",
    "| **TorchRL** | RL con PyTorch (oficial) | `pip install torchrl` |\n",
    "\n",
    "## Papers Fundamentales\n",
    "\n",
    "| AÃ±o | Paper | ContribuciÃ³n |\n",
    "|-----|-------|--------------|\n",
    "| 2013 | Playing Atari with Deep RL | Primer DQN exitoso |\n",
    "| 2015 | Human-level control through deep RL | DQN en Nature, Experience Replay + Target Network |\n",
    "| 2016 | Asynchronous Methods for Deep RL | A3C: Entrenamiento paralelo |\n",
    "| 2017 | Proximal Policy Optimization | PPO: Algoritmo robusto y simple |\n",
    "| 2018 | Soft Actor-Critic | SAC: Estado del arte en control continuo |\n",
    "\n",
    "## Entornos Interesantes para Explorar\n",
    "\n",
    "| Entorno | InstalaciÃ³n | DescripciÃ³n |\n",
    "|---------|-------------|-------------|\n",
    "| Atari | `pip install gymnasium[atari,accept-rom-license]` | Videojuegos clÃ¡sicos |\n",
    "| Box2D | `pip install gymnasium[box2d]` | LunarLander, CarRacing |\n",
    "| MuJoCo | `pip install gymnasium[mujoco]` | RobÃ³tica 3D (ahora gratuito) |\n",
    "| Minigrid | `pip install minigrid` | Laberintos 2D personalizables |\n",
    "| Highway | `pip install highway-env` | ConducciÃ³n autÃ³noma |\n",
    "| PettingZoo | `pip install pettingzoo` | Multi-agente |\n",
    "\n",
    "---\n",
    "\n",
    "**Â¡Buena suerte con tu prÃ¡ctica!**\n",
    "\n",
    "Recuerda: El RL requiere **paciencia**. Es normal que los agentes tarden en aprender o que los primeros intentos no funcionen. Â¡Experimenta, ajusta hiperparÃ¡metros, y disfruta del proceso!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}