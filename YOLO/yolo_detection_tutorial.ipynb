{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO Video Detection con Supervision\n",
    "\n",
    "Este notebook muestra cómo usar YOLO (v8-v11) con la librería **supervision** para:\n",
    "- Detectar objetos en imágenes y video\n",
    "- Tracking de objetos (seguimiento entre frames)\n",
    "- Anotaciones visuales (bounding boxes, etiquetas, trazas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Instalación e Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar dependencias (ejecutar solo la primera vez)\n",
    "# !pip install ultralytics supervision opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import supervision as sv\n",
    "from ultralytics import YOLO\n",
    "from IPython.display import display, Image, Video, clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"Supervision version: {sv.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cargar el Modelo YOLO\n",
    "\n",
    "Modelos disponibles (de más rápido a más preciso):\n",
    "- `yolo11n.pt` - Nano (más rápido)\n",
    "- `yolo11s.pt` - Small\n",
    "- `yolo11m.pt` - Medium\n",
    "- `yolo11l.pt` - Large\n",
    "- `yolo11x.pt` - Extra Large (más preciso)\n",
    "\n",
    "También puedes usar `yolov8*.pt`, `yolov9*.pt`, `yolov10*.pt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar modelo (se descarga automáticamente la primera vez)\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "# Ver las clases que puede detectar\n",
    "print(f\"Clases disponibles ({len(model.names)}):\")\n",
    "print(list(model.names.values())[:20], \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Detección en una Imagen\n",
    "\n",
    "Primero probamos con una imagen estática para entender el flujo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capturar una imagen de la webcam (o cargar de archivo)\n",
    "cap = cv2.VideoCapture(0)\n",
    "ret, frame = cap.read()\n",
    "cap.release()\n",
    "\n",
    "if ret:\n",
    "    # Convertir BGR -> RGB para visualizar\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"Imagen original\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No se pudo capturar imagen. Usando imagen de ejemplo.\")\n",
    "    # Crear imagen de prueba\n",
    "    frame = np.zeros((480, 640, 3), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar detección YOLO\n",
    "results = model(frame, conf=0.5, verbose=False)[0]\n",
    "\n",
    "# Convertir a formato supervision\n",
    "detections = sv.Detections.from_ultralytics(results)\n",
    "\n",
    "print(f\"Objetos detectados: {len(detections)}\")\n",
    "print(f\"\\nDetalles de detecciones:\")\n",
    "for i, (xyxy, conf, class_id) in enumerate(zip(detections.xyxy, detections.confidence, detections.class_id)):\n",
    "    print(f\"  {i+1}. {model.names[class_id]}: {conf:.2%} - bbox: {xyxy.astype(int)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear anotadores\n",
    "box_annotator = sv.BoxAnnotator(thickness=2)\n",
    "label_annotator = sv.LabelAnnotator(text_thickness=1, text_scale=0.5)\n",
    "\n",
    "# Generar etiquetas\n",
    "labels = [\n",
    "    f\"{model.names[class_id]} {conf:.2f}\"\n",
    "    for class_id, conf in zip(detections.class_id, detections.confidence)\n",
    "]\n",
    "\n",
    "# Anotar imagen\n",
    "annotated = frame.copy()\n",
    "annotated = box_annotator.annotate(annotated, detections=detections)\n",
    "annotated = label_annotator.annotate(annotated, detections=detections, labels=labels)\n",
    "\n",
    "# Visualizar\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB))\n",
    "plt.title(f\"Detección YOLO - {len(detections)} objetos\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Tracking de Objetos\n",
    "\n",
    "**ByteTrack** asigna IDs únicos a cada objeto y los mantiene entre frames.\n",
    "\n",
    "Esto permite:\n",
    "- Contar objetos únicos\n",
    "- Seguir trayectorias\n",
    "- Analizar comportamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear tracker\n",
    "tracker = sv.ByteTrack()\n",
    "\n",
    "# Aplicar tracking a las detecciones\n",
    "detections_tracked = tracker.update_with_detections(detections)\n",
    "\n",
    "print(\"Detecciones con tracking:\")\n",
    "if detections_tracked.tracker_id is not None:\n",
    "    for tid, class_id, conf in zip(detections_tracked.tracker_id, \n",
    "                                    detections_tracked.class_id, \n",
    "                                    detections_tracked.confidence):\n",
    "        print(f\"  ID #{tid}: {model.names[class_id]} ({conf:.2%})\")\n",
    "else:\n",
    "    print(\"  No hay objetos trackeados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Procesar Video Completo\n",
    "\n",
    "Usamos `sv.process_video()` para procesar un archivo de video frame por frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración\n",
    "VIDEO_INPUT = \"test_video.mp4\"   # Cambia por tu video\n",
    "VIDEO_OUTPUT = \"output_notebook.mp4\"\n",
    "CONFIDENCE = 0.5\n",
    "\n",
    "# Reiniciar tracker para nuevo video\n",
    "tracker = sv.ByteTrack()\n",
    "\n",
    "# Crear anotadores\n",
    "box_annotator = sv.BoxAnnotator(thickness=2)\n",
    "label_annotator = sv.LabelAnnotator(text_thickness=1, text_scale=0.5)\n",
    "trace_annotator = sv.TraceAnnotator(thickness=2, trace_length=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_frame(frame: np.ndarray, frame_idx: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Callback que procesa cada frame del video.\n",
    "    \n",
    "    Args:\n",
    "        frame: Imagen BGR del frame actual\n",
    "        frame_idx: Índice del frame (0, 1, 2, ...)\n",
    "    \n",
    "    Returns:\n",
    "        Frame anotado con detecciones\n",
    "    \"\"\"\n",
    "    # 1. Detección YOLO\n",
    "    results = model(frame, conf=CONFIDENCE, verbose=False)[0]\n",
    "    detections = sv.Detections.from_ultralytics(results)\n",
    "    \n",
    "    # 2. Tracking\n",
    "    detections = tracker.update_with_detections(detections)\n",
    "    \n",
    "    # 3. Generar etiquetas con ID de tracking\n",
    "    if detections.tracker_id is not None:\n",
    "        labels = [\n",
    "            f\"#{tid} {model.names[cid]} {conf:.2f}\"\n",
    "            for tid, cid, conf in zip(\n",
    "                detections.tracker_id,\n",
    "                detections.class_id,\n",
    "                detections.confidence\n",
    "            )\n",
    "        ]\n",
    "    else:\n",
    "        labels = [\n",
    "            f\"{model.names[cid]} {conf:.2f}\"\n",
    "            for cid, conf in zip(detections.class_id, detections.confidence)\n",
    "        ]\n",
    "    \n",
    "    # 4. Anotar frame\n",
    "    annotated = frame.copy()\n",
    "    annotated = box_annotator.annotate(annotated, detections=detections)\n",
    "    annotated = label_annotator.annotate(annotated, detections=detections, labels=labels)\n",
    "    annotated = trace_annotator.annotate(annotated, detections=detections)\n",
    "    \n",
    "    # Mostrar progreso cada 50 frames\n",
    "    if frame_idx % 50 == 0:\n",
    "        print(f\"Frame {frame_idx}...\")\n",
    "    \n",
    "    return annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar que existe el video de entrada\n",
    "import os\n",
    "if os.path.exists(VIDEO_INPUT):\n",
    "    # Info del video\n",
    "    video_info = sv.VideoInfo.from_video_path(VIDEO_INPUT)\n",
    "    print(f\"Video de entrada: {VIDEO_INPUT}\")\n",
    "    print(f\"  Resolución: {video_info.width}x{video_info.height}\")\n",
    "    print(f\"  FPS: {video_info.fps}\")\n",
    "    print(f\"  Total frames: {video_info.total_frames}\")\n",
    "    print(f\"  Duración: {video_info.total_frames / video_info.fps:.1f}s\")\n",
    "else:\n",
    "    print(f\"⚠️ No se encontró '{VIDEO_INPUT}'\")\n",
    "    print(\"Descarga un video de prueba o cambia VIDEO_INPUT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesar video (solo si existe)\n",
    "if os.path.exists(VIDEO_INPUT):\n",
    "    print(f\"\\nProcesando video...\")\n",
    "    \n",
    "    sv.process_video(\n",
    "        source_path=VIDEO_INPUT,\n",
    "        target_path=VIDEO_OUTPUT,\n",
    "        callback=process_frame\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n✅ Video guardado en: {VIDEO_OUTPUT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Detección en Tiempo Real (Webcam)\n",
    "\n",
    "⚠️ **Nota**: Este código abre una ventana de OpenCV. En algunos entornos de notebook puede no funcionar correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_webcam_detection(duration_seconds: int = 30):\n",
    "    \"\"\"\n",
    "    Ejecuta detección en webcam por un tiempo determinado.\n",
    "    Presiona 'q' para salir antes.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: No se puede abrir la webcam\")\n",
    "        return\n",
    "    \n",
    "    # Reiniciar tracker\n",
    "    tracker = sv.ByteTrack()\n",
    "    \n",
    "    # Anotadores\n",
    "    box_annotator = sv.BoxAnnotator(thickness=2)\n",
    "    label_annotator = sv.LabelAnnotator(text_thickness=1, text_scale=0.5)\n",
    "    trace_annotator = sv.TraceAnnotator(thickness=2, trace_length=50)\n",
    "    \n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) or 30\n",
    "    max_frames = int(duration_seconds * fps)\n",
    "    frame_count = 0\n",
    "    \n",
    "    print(f\"Iniciando detección por {duration_seconds}s. Presiona 'q' para salir.\")\n",
    "    \n",
    "    while frame_count < max_frames:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Detección\n",
    "        results = model(frame, conf=0.5, verbose=False)[0]\n",
    "        detections = sv.Detections.from_ultralytics(results)\n",
    "        detections = tracker.update_with_detections(detections)\n",
    "        \n",
    "        # Etiquetas\n",
    "        if detections.tracker_id is not None:\n",
    "            labels = [f\"#{tid} {model.names[cid]}\" \n",
    "                      for tid, cid in zip(detections.tracker_id, detections.class_id)]\n",
    "        else:\n",
    "            labels = [model.names[cid] for cid in detections.class_id]\n",
    "        \n",
    "        # Anotar\n",
    "        annotated = box_annotator.annotate(frame.copy(), detections)\n",
    "        annotated = label_annotator.annotate(annotated, detections, labels=labels)\n",
    "        annotated = trace_annotator.annotate(annotated, detections)\n",
    "        \n",
    "        # Mostrar\n",
    "        cv2.imshow(\"YOLO Webcam\", annotated)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "        frame_count += 1\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(f\"Detección finalizada. Frames procesados: {frame_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descomentar para ejecutar webcam (30 segundos)\n",
    "# run_webcam_detection(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Resumen de la Arquitectura\n",
    "\n",
    "```\n",
    "┌─────────────┐     ┌─────────────────┐     ┌─────────────┐     ┌─────────────┐\n",
    "│   Frame     │ ──► │  YOLO Model     │ ──► │  ByteTrack  │ ──► │  Annotators │\n",
    "│   (imagen)  │     │  model(frame)   │     │  tracker()  │     │  annotate() │\n",
    "└─────────────┘     └─────────────────┘     └─────────────┘     └─────────────┘\n",
    "                            │                      │                    │\n",
    "                            ▼                      ▼                    ▼\n",
    "                    ┌───────────────┐      ┌────────────┐       ┌────────────┐\n",
    "                    │ Detections:   │      │ + tracker_ │       │ Frame con  │\n",
    "                    │ - xyxy        │      │   id       │       │ boxes,     │\n",
    "                    │ - confidence  │      │ (IDs       │       │ labels,    │\n",
    "                    │ - class_id    │      │  únicos)   │       │ traces     │\n",
    "                    └───────────────┘      └────────────┘       └────────────┘\n",
    "```\n",
    "\n",
    "### Clases Principales de Supervision\n",
    "\n",
    "| Clase | Uso |\n",
    "|-------|-----|\n",
    "| `sv.Detections` | Contenedor de detecciones (xyxy, conf, class_id, tracker_id) |\n",
    "| `sv.ByteTrack` | Algoritmo de tracking multi-objeto |\n",
    "| `sv.BoxAnnotator` | Dibuja bounding boxes |\n",
    "| `sv.LabelAnnotator` | Dibuja etiquetas de texto |\n",
    "| `sv.TraceAnnotator` | Dibuja trazas de movimiento |\n",
    "| `sv.process_video()` | Procesa video frame por frame |\n",
    "| `sv.VideoInfo` | Metadatos del video (resolución, fps, frames) |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
